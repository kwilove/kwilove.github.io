{"meta":{"title":"子敬的博客","subtitle":null,"description":"子敬的博客","author":"子敬","url":"https://kwilove.github.io","root":"/"},"pages":[],"posts":[{"title":"了解MySQL的explain命令","slug":"了解MySQL的explain命令","date":"2019-05-23T14:12:40.000Z","updated":"2019-05-23T14:15:42.664Z","comments":true,"path":"2019/05/23/了解MySQL的explain命令/","link":"","permalink":"https://kwilove.github.io/2019/05/23/了解MySQL的explain命令/","excerpt":"","text":"一. 预备知识阅读本文章前需要掌握MySQL索引的底层数据结构相关知识，可以查看我之前的文章了解。 索引前导列: 所谓前导列，就是联合索引的第一列或者从第一列开始连续多列的组合。比如通过语句CREATE INDEX table1_index ON table1 (x, y, z)创建索引，那么x、xy、xyz都是前导列，而yz，y，z这样的就不是。 覆盖索引: 覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据表，换句话说查询列要被所建的索引覆盖。 二. explain命令的作用 使用explain关键字可以模拟优化器执行SQL语句，知道MySQL是如何处理你的SQL语句的，从而分析你的查询语句的性能瓶颈。 在select语句前添加explain关键字，MySQL会在查询上设置一个标记，在执行查询时，会返回执行计划信息，而不是返回查询语句的执行结果；如果from子句中包含select语句，该子查询依然会被执行，并且子查询的结果会产生临时表。 三. explain讲解需要使用的表 Actor演员表 12345678910111213141516DROP TABLEIF EXISTS `actor`;CREATE TABLE `actor` ( `id` INT (11) NOT NULL, `name` VARCHAR (45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `actor` (`id`, `name`, `update_time`)VALUES (1,'a','2017-12-22 15:27:18'), (2,'b','2017-12-22 15:27:18'), (3,'c','2017-12-22 15:27:18'); film影片表 12345678910111213141516DROP TABLEIF EXISTS `film`;CREATE TABLE `film` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `name` VARCHAR (10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `film` (`id`, `name`)VALUES (3, 'film0'), (1, 'film1'), (2, 'film2'); film_actor影片演员关联表 123456789101112131415161718DROP TABLEIF EXISTS `film_actor`;CREATE TABLE `film_actor` ( `id` INT (11) NOT NULL, `film_id` INT (11) NOT NULL, `actor_id` INT (11) NOT NULL, `remark` VARCHAR (255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`, `actor_id`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`)VALUES (1, 1, 1), (2, 1, 2), (3, 2, 1); 举例讲解mysql&gt; explain select * from actor; id列 id列是select的序列号，id的个数等于SQL语句中select的个数，并且id列的顺序与select出现的顺序一一对应、 id的值越大，对应的select语句执行优先级越高，也就是越早执行；id相同则从上往下执行，id为NULL是最后执行。 MySQL中的select语句分为： 简单查询SIMPLE 复杂查询PRIMARY 简单子查询 派生表，指from语句中的子查询 union查询 1.简单子查询 1explain select (select 1 from actor limit 1) from film; ![](/styles/images/mysql/2.png) from子句子查询 1explain select id from (select id from film) as der; 这条查询语句执行时产生了一张临时表der，外部select引用了这张临时表。 union查询 1explain select 1 union all select 1; union执行结果总是放在一个匿名临时表中，因为这种临时表不在SQL中出现，所以它的id是NULL。 select_type列select_type列表示对应的select是简单查询还是复杂查询，如果是复杂查询又是哪种复杂查询。 SIMPLE: 简单查询，不包含子查询和union查询 1explain select * from film where id = 2; PRIMARY: 复杂查询中最外层的select SUBQUERY: 包含在select中的子查询，不再from子句中 DERIVED: 包含在from子句中的子查询，MySQL会将结果存放在一个临时表中，也称为派生表 1explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der; UNION: 在union语句中的第二个和后面的select UNION RESULT: 在union匿名临时表中查询的select 1explain select 1 union all select 1; table列 table列表示explain中的select语句正在访问哪张表。 当from子句中有子查询时，table列为&lt;derivenN&gt;格式，表示当前查询依赖id=N的查询，于是先执行id=N的查询。 当有union时，UNION RESULT的table列的值是&lt;union1,2&gt;，其中1和2表示参与union的select的id。 type列这一列表示查询语句是关联类型还是访问类型，查找数据行记录的大概范围。type列数值从最优到最差的排序是：1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL。 在日常的开发中，我们建议确保查询能达到range以上，最好达到ref。 NULL: MySQL能够在优化阶段分解查询语句，在执行阶段不用再访问表或索引。例如，在索引列中选取最小值，可以通过查找索引完成，并不需要在执行时访问数据表。从下面的执行计划结果能看到table列为NULL，说明这条查询语句并没有访问表，而是直接查找索引得出结果。 1explain select min(id) from film; const: 当我们使用primary key或unique key的所在列与常量进行等值比较时，可以猜到查询结果只能是0条记录或者1条记录，这个结果的记录数是一个可预见常量，因此使用const标识。 system: system是const的一种特例，如果数据表中只有一条记录的话，那么我们查询的结果也最多是一条记录，这时结果记录数也是一个可预见常量，因此用system标识。 1explain extended select * from (select * from film where id = 1) tmp; eq_ref: 当使用关联查询（join）时，如果在关联条件join on中使用的字段是primary key或unique key，就会被标识为eq_ref。 1explain select * from film_actor left join film on film_actor.film_id = film.id; 如上图中显示的第二行film表的查询记录，因为在join on条件中使用的film.id就是film表的primary key，所以film表的查询计划结果行的type列为eq_ref。 ref: 相比于eq_ref的区别是查询条件中使用的字段是普通索引，或者是联合索引的前导列，下面列出两种出现ref类型的场景： 简单select查询，name是普通索引。 1explain select * from film where name = \"film1\"; 关联selevt查询。 1explain select film_id from film left join film_actor on film.id = film_actor.film_id; idx_film_actor_id是包含film_id和actor_id字段的联合索引，关联查询中使用到了film_actor表联合索引idx_film_actor_id的前导列film_id。 range: 使用索引字段进行范围查找，通常是in()、between…and…、&gt;、&gt;=、&lt;、&lt;=等操作。 1explain select * from actor where id &gt; 1; index: 扫描索引，通常是比ALL快一些，index是从索引中读取数据，ALL从硬盘中读取， 1explain select * from film; 因为film表中所有字段都走了索引，所以MySQL通过扫描索引取到了数据，因此没有再扫描表。 ALL: 全表扫描，意味着MySQL需要从头到尾的查找需要的行，遇到这种情况通常都是需要增加索引进行优化。 1explain select * from actor; possible_keys列这一列显示MySQL分析查询语句时可能使用到的索引。如果该列显示NULL，表示不使用索引查询，在这种情况下，通常我们都需要检查where子句，通过创建适当的索引优化查询性能。 key列 这一列显示了MySQL真正执行查询语句时使用到的索引。如果查询操作没有使用索引，则该列为NULL； 通过explain分析查询语句时可能会出现possible_keys列有值，但key列为NULL的情况，原因是表中数据不多，虽然MySQL分析出可能使用哪些索引，但是实际执行时认为索引对本次查询没什么帮助，选择了全表查询。 如果想强制使用possible_keys列中分析出的索引，可以在查询中使用force index、反之强制不使用possible_keys列的索引需要使用ignore index。 key_len列 这一列显示查询时使用的索引的字节数总和，在使用到联合索引时能通过该值分析出使用到了索引中的那些字段。 key_len的计算规则： 字符串 char(n): n为字节长度 varchar(n): 需要2个字节用于存储字符串长度，在使用utf-8字符集时，长度计算公式是3n + 2 数值类型 tinyint: 1字节 smallint: 2字节 int: 4字节 bigint: 8字节 时间类型 date: 3字节 timestamp: 4字节 datatime: 8字节 如果字段允许为NULL，还需要1字节用于记录是否为NULL 索引的最大长度为768字节，当字符串过长时，MySQL会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 样例说明：在film_actor表中创建了一个联合索引idx_film_actor_id，它由film_id和actor_id两个int类型字段组成。 执行下面的语句并得到结果 1explain select * from film_actor where film_id = 2; 按照我们上面的计算规则每个int是4字节，结果中key_len=4说明使用了film_id列进行索引查询。 执行另一条语句并得到结果 1explain select * from film_actor where film_id = 2 and actor_id = 1; 结果中key_len=8，刚好是film_id和actor_id字节之和。 ref列这一列显示在key列中列出的每个索引分别和什么类型的操作数做判断。 const（常量） 1explain select * from film_actor where film_id = 2; where子句film_id = 2中film_id是联合索引的前导列，2是常量，因此ref=const。 字段名 1explain select film_actor.film_id from film left join film_actor on film.id = film_actor.film_id; 我们看图中第二行是film_actor表的结论，关联条件是film.id = film_actor.film_id，其中film_actor.film_id是联合索引前导列，film.id是关联表字段，因此ref=test.film.id（数据库.表名.字段名）， rows列这一列显示的是MySQL估计需要读取和检测的行数，注意这里不是结果集里的行数。 Extra列这一列显示额外信息，常见的值如下: Using index: 查询的所有列被索引覆盖，并且where筛选条件（如果有where子句）是索引的前导列，这种结果代表了查询性能高效，一般是使用了覆盖索引。 12-- film_id列是film_actor表中联合索引idx_film_actor_id的前导列 explain select film_id from film_actor where film_id = 1; Using where; Using index: 查询的列被索引覆盖，并且where的筛选条件是索引列之一，但不是前导列，这种情况无法直接通过索引查找方式查询出符合条件的数据。 1explain select film_id from film_actor where actor_id = 1; Using where: 查询的列未被索引全部覆盖，并且where子句的筛选条件也不是索引的前导列。 1explain select * from actor where name = 'a'; NULL: 查询的列未被索引覆盖，但是where筛选条件是索引的前导列。可以这么理解，where子句走了索引，但是需要select的数据列不能全部从索引中获取，需要通过索引回表查询。 1explain select * from film_actor where film_id = 1; Using index condition: 与Using where类似，查询的列未被索引全部覆盖，where筛选条件是索引的前导列而且是一个范围查找。 1explain select * from film_actor where film_id &gt; 1; Using temporary: MySQL需要创建一张临时表来处理查询，这种情况一般都是需要优化的，可以考虑索引优化。 我们可以通过分析actor表和film表的name列去重查询进行分析对比，如下: actor表去重查询name: 1explain select distinct name from actor; 因为actor表的name没有加索引，所以MySQL创建了张临时表后再做去重。 film表去重查询name: 1explain select distinct name from film; 因为film表的name建立了idx_name索引，所以查询时Extra列显示为Using index，没有创建临时表。 Using filesort: MySQL对查询结果集进行了外部排序，而不是按照索引次序从表里读取行数据。这种情况下MySQL会扫描所出所有符合条件的记录，并记录排序关键字和行指针，然后对关键字排序并按顺序检索出行信息，遇到这种情况需要考虑使用索引优化查询。 为了方便理解，我们列举两条查询语句对explain结果进行分析对比。 按name排序查询actor表 1explain select * from actor order by name; 按name排序查询film表 1explain select * from film order by name; 从上面的执行结果可以看出，按name排序查询actor表时Extra=Using filesort，也就是对查询结果集做了外部排序；但按name排序查询film表时Extra=Using index；相同类型的查询语句，只是查询的表不同，为什么Extra的值不同呢？原因就是film表的name列加了索引，看过我之前文章的朋友应该都知道MySQL索引是一种排好序的数据结构，因此按name排序查询film表数据实际上是按照索引的顺序查询数据的，不需要再进行外部排序。 Extra是一个很复杂的项，在这里没法全部说明，需要大家自己去了解。","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://kwilove.github.io/tags/MySQL/"}]},{"title":"数据库事务特性及隔离级别","slug":"数据库事务特性及隔离级别","date":"2019-05-23T14:11:39.000Z","updated":"2019-05-23T14:12:23.493Z","comments":true,"path":"2019/05/23/数据库事务特性及隔离级别/","link":"","permalink":"https://kwilove.github.io/2019/05/23/数据库事务特性及隔离级别/","excerpt":"","text":"事务的四个基本特性（ACID） 1. 原子性（Atomicity）： 同一个事务所包含的所有操作，要么全做，要么全不做，任何一项操作的失败都会导致整个事务的失败； 2. 一致性（Consistency）： 当事务结束后，系统在执行事务操作前后的状态是一致的； 这里举个例子来说，比如A（余额300元）转账给B（余额200元），在一个事务中，无论A转了多少钱，转了几次，在事务完成后，A和B的总金额还是500元； 3. 隔离性（Durability） 并发执行的多个事务操作是相互隔离，互不影响的，并且无法看到其他事务的中间状态； 数据库提供了多种隔离级别，这块后面会说道。 4. 持久性 事务完成后所做的所有改动都会被持久化，永久生效，即使数据库发生了灾难性故障也不会对已经完成的事务结果造成影响。 事务隔离级别 在高并发情况下，要完成保证事务ACID特性是十分困难的，除非把所有的事务串行化执行，但是因此造成的影响将是系统性能大大降低。在实际开发中很多业务对事务的要求是不一样的，因此数据库设计了四种隔离级别供用户基于业务进行选择。| 隔离级别 | 脏读（Dirty Read） | 不可重复读（Non-repeatable Read） | 幻读（Phantom Read） ||–|–|–|–||读未提交（Read uncommitted）|可能|可能|可能||读已提交（Read committed）|不可能|可能|可能|可重复读（Repeatable read）|不可能|不可能|可能||串行化（Serializable）|不可能|不可能|不可能| 脏读：一个事务读取到另一个事务还未提交的数据。 不可重复读：在同一个事务中，前后两次执行相同的查询操作，出现返回的结果不一致的情况，换言之就是后一次查询操作能够读取到其他事务已提交的更新数据；“可重复读” 与之相反，是指在同一个事务中，前后两次查询操作读取到的结果一致，其他事务提交的更新数据不会对本事务造成影响。 幻读：查询表中一条记录，如果发现不存在就插入一条，并发情况下，发现表中出现两条相同记录，这就是幻读。 数据库默认的隔离级别 Oracle默认隔离级别是Read committed； MySQL默认是Repeatable read，另外在MySQL中执行一条查询语句默认是一个独立事务操作，所以看上去效果跟Read committed一样； 查看MySQL隔离级别信息： 1select @@tx_isolation; 设置MySQL隔离级别： 1set [global|session] transaction isolation level 隔离级别名称; 或 1set tx_isolation=’隔离级别名称;’ 可选参数： READ-UNCOMMITTED READ-COMMITTED REPEATABLE-READ SERIALIZABLE","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"数据库事务","slug":"数据库事务","permalink":"https://kwilove.github.io/tags/数据库事务/"}]},{"title":"Springboot加载自定义yml文件配置的方法","slug":"Springboot加载自定义yml文件配置的方法","date":"2019-05-23T14:10:06.000Z","updated":"2019-05-23T14:11:14.048Z","comments":true,"path":"2019/05/23/Springboot加载自定义yml文件配置的方法/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Springboot加载自定义yml文件配置的方法/","excerpt":"","text":"Springboot在1.5.x版本之后，去除了@ConfigurationProperties注解中的location参数，因此无法再通过这种方式加载自定义的yml配置文件了。 我在网上看到很多资料都是这么说明的，我也没去验证，先不管吧，总之我搜集资料后特意总结了以下三种解决方法，亲测有效。 首先先在resources目录下创建一个测试用的yml配置文件，内容如下： PS：注意yml文件中key: value的冒号后面是有一个空格的 12345system: user: name: zjhuang password: 123456 age: 25 一. @ConfigurationProperties + @PropertySource + @Value注解方式 配置参数类代码： 这种方法必须配置@ConfigurationProperties中的prefix前缀信息，否则无法获取到yml数据。 @PropertySource是为了告知springboot加载自定义的yml配置文件，springboot默认会自动加载application.yml文件，如果参数信息直接写在这个文件里，则不需要显式加载。 在@ConfigurationProperties中配置了prefix前缀信息的条件下，@Value指定yml配置文件中的参数项名称。 123456789101112131415161718192021import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = \"system.user\")@PropertySource(value = \"classpath:test.yml\")public class YamlProperties &#123; @Value(\"$&#123;name&#125;\") private String name; @Value(\"$&#123;password&#125;\") private String password; @Value(\"$&#123;age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 测试用例代码： 后面的两种方式也共用这个测试用例代码，下面不再列出。 123456789101112131415161718import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)public class TestYamlLoader &#123; @Autowired private YamlProperties yamlProperties; @Test public void test() &#123; System.out.println(yamlProperties.toString()); &#125;&#125; 输出结果：1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 二. 实现PropertySourceFactory接口 + @PropertySource + @Value方式 PropertySourceFactory实现类代码 12345678910111213141516171819202122232425import org.springframework.boot.env.PropertySourcesLoader;import org.springframework.core.env.PropertySource;import org.springframework.core.io.Resource;import org.springframework.core.io.support.EncodedResource;import org.springframework.core.io.support.PropertySourceFactory;import org.springframework.util.StringUtils;import java.io.IOException;public class YamlPropertySourceFactory implements PropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource encodedResource) throws IOException &#123; return name != null ? new PropertySourcesLoader().load(encodedResource.getResource(), name, null) : new PropertySourcesLoader().load( encodedResource.getResource(), getNameForResource(encodedResource.getResource()), null); &#125; private static String getNameForResource(Resource resource) &#123; String name = resource.getDescription(); if (!StringUtils.hasText(name)) &#123; name = resource.getClass().getSimpleName() + \"@\" + System.identityHashCode(resource); &#125; return name; &#125;&#125; 配置参数类代码 12345678910111213141516171819import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;@Component@PropertySource(value = \"classpath:test.yml\", factory = YamlPropertySourceFactory.class)public class YamlProperties &#123; @Value(\"$&#123;system.user.name&#125;\") private String name; @Value(\"$&#123;system.user.password&#125;\") private String password; @Value(\"$&#123;system.user.age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 跟第一种方法不同点在于： 1、放弃了@ConfigurationProperties注解，改为实现了PropertySourceFactory接口 2、@PropertySource注解定义了factory属性，值为上一步中PropertySourceFactory实现类的class 3、@Value注解中使用了参数在yml’文件中的全限定名 输出结果： 1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 三.使用YamlPropertiesFactoryBean + @Value方式 PropertySourcesPlaceholderConfigurer类代码 1234567891011121314151617import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.context.annotation.Bean;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.io.ClassPathResource;import org.springframework.stereotype.Component;@Componentpublic class PropertySourcesPlaceholderConfigurerBean &#123; @Bean public PropertySourcesPlaceholderConfigurer yaml() &#123; PropertySourcesPlaceholderConfigurer configurer = new PropertySourcesPlaceholderConfigurer(); YamlPropertiesFactoryBean yaml = new YamlPropertiesFactoryBean(); yaml.setResources(new ClassPathResource(\"test.yml\")); configurer.setProperties(yaml.getObject()); return configurer; &#125;&#125; 配置参数类代码 这第三种方法去掉了@PropertySource 注解，改为定义一个PropertySourcesPlaceholderConfigurer类型的@Bean来加载配置文件信息。 12345678910111213141516171819202122import org.springframework.beans.factory.annotation.Value;import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.context.annotation.Bean;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.io.ClassPathResource;import org.springframework.stereotype.Component;@Componentpublic class YamlProperties &#123; @Value(\"$&#123;system.user.name&#125;\") private String name; @Value(\"$&#123;system.user.password&#125;\") private String password; @Value(\"$&#123;system.user.age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 输出结果： 1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 以上就是springboot加载自定义yml配置信息的三种方法，大家按照自己喜好选择使用即可；第三种方法好像只能用于加载一个yml文件的情况，第一和第二种方法可以实现加载多个yml文件，@PropertySources的value参数是支持数组赋值的。 1@PropertySource(value = &#123;&quot;classpath:test1.yml&quot;, &quot;classpath:test2.yml&quot;&#125;) 另外需要提一点的是，不管是加载几个yml文件，@Value修饰的所有参数都必须在yml文件中定义齐全，yml缺少配置的话会抛出无法解析占位符的异常 1Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder &apos;age&apos; in value &quot;$&#123;age&#125;&quot;","categories":[{"name":"技巧","slug":"技巧","permalink":"https://kwilove.github.io/categories/技巧/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"https://kwilove.github.io/tags/Springboot/"}]},{"title":"Redis核心原理","slug":"Redis核心原理","date":"2019-05-23T14:07:38.000Z","updated":"2019-05-23T14:09:45.253Z","comments":true,"path":"2019/05/23/Redis核心原理/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Redis核心原理/","excerpt":"","text":"Redis的单线程和高性能 Redis单线程为什么还能那么快？ 因为它所有的数据都存储在内存中，所有的运算都是内存级别的运算。 单线程避免了线程间切换的性能损耗。 正因为redis是单线程的，所以要谨慎使用那些耗时指令，比如keys，否则会导致redis卡顿。 Redis在单线程模式下如何做到高效处理并发客户端连接？ Redis通过epoll（IO多路复用模型）实现将客户端连接信息和事件放入队列，然后由文件事件分派器依次分发给对应的事件处理器。 Nginxy也是采用IO多路复用模型解决了C10K（10K并发连接数）问题。 Redis的持久化Redis 提供了多种不同级别的持久化方式： RDB快照 RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。 你也可以通过调用 SAVE 或者 BGSAVE ， 手动让 Redis 进行数据集保存操作；比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集： 1save 60 1000 AOF持久化 AOF持久化会记录Redis服务器执行过的所有写操作指令，并在服务器启动时，通过重新执行这些指令来还原数据集， 参考 Redis持久化","categories":[{"name":"分布式框架","slug":"分布式框架","permalink":"https://kwilove.github.io/categories/分布式框架/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://kwilove.github.io/tags/Redis/"}]},{"title":"2019-05-23-Redis基础数据结构","slug":"Redis基础数据结构","date":"2019-05-23T09:33:23.000Z","updated":"2019-05-23T14:06:30.262Z","comments":true,"path":"2019/05/23/Redis基础数据结构/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Redis基础数据结构/","excerpt":"","text":"Redis有5种基础数据结构：string字符串、list列表、set集合、hash哈希和zset有序集合。Redis的所有数据结构都是一个唯一的字符串类型key作为名称，然后通过这个key值获取相应的value，Redis中5种数据结构就是体现在value上的。 string（字符串）string字符串时Redis最简单的数据结构，它的使用非常广泛；常见场景：比如用于缓存用户信息，我们将用户信息结构体通过JSON序列化成字符串放进Redis中缓存，取用户信息时会经过一个反序列化。单个键值对操作 set、get： 1234567891011127.0.0.1:6379&gt; set desc \"today is 2019-01-26\"OK127.0.0.1:6379&gt; get desc\"today is 2019-01-26\"127.0.0.1:6379&gt; exists desc(integer) 1127.0.0.1:6379&gt; del desc(integer) 1127.0.0.1:6379&gt; get desc(nil)127.0.0.1:6379&gt; 批量键值对操作 mset、mget：可以批量对多个字符串进行读写，节省网络耗时开销 1234567891011121314127.0.0.1:6379&gt; set lang1 chineseOK127.0.0.1:6379&gt; set lang2 englishOK127.0.0.1:6379&gt; mget lang1 lang2 lang31) \"chinese\"2) \"english\"3) (nil)127.0.0.1:6379&gt; mset book1 java book2 c++ book3 pythonOK127.0.0.1:6379&gt; mget book1 book2 book31) \"java\"2) \"c++\"3) \"python\" 过期命令expire和setex，可以对key设置过期时间，到点后自动删除，这个功能经常用于设置缓存失效时间： expire key secordssecords为过期时间，单位时秒 123456789127.0.0.1:6379&gt; set city guangzhouOK127.0.0.1:6379&gt; get city\"guangzhou\"127.0.0.1:6379&gt; expire city 5(integer) 1# 等待5s过后127.0.0.1:6379&gt; get city(nil) setex key secords valuesecords为过期时间，单位时秒，等价于set + expire 1234567127.0.0.1:6379&gt; setex city 5 guangzhouOK127.0.0.1:6379&gt; get city\"guangzhou\"# 等待5s过后127.0.0.1:6379&gt; get city(nil) set的其他扩展命令 setnx key value当key不存在时执行set操作 12345678127.0.0.1:6379&gt; setnx num 001(integer) 1127.0.0.1:6379&gt; get num\"001\"127.0.0.1:6379&gt; setnx num 002(integer) 0 # 因为num已经存在，所以此处设置不成功127.0.0.1:6379&gt; get num\"001\" # num的值没有改变 原子计数：如果value值设置成一个整数，Redis还支持对它记性自增、自减操作，自增自减时有范围的，它的范围时signed long的最大最小值，超过这个范围Redis会报错。 123456789101112127.0.0.1:6379&gt; set age 25OK127.0.0.1:6379&gt; incr age(integer) 26127.0.0.1:6379&gt; incrby age 10(integer) 36127.0.0.1:6379&gt; incrby age -5(integer) 31127.0.0.1:6379&gt; set max 9223372036854775807OK127.0.0.1:6379&gt; incr max(error) ERR increment or decrement would overflow list（列表）Redis的list相当于Java中的LinkedList，它是一个链表结构而不是数组结构，因此它具备链表的优、缺点；优点：list的插入和删除操作效率高，时间复杂度喂O(1)；缺点：list的查询或索引定位比较慢，时间复杂度喂O(n)；此外，列表的特性就是先进先出，当list弹出最后一个元素之后该数据结构自动被删除，同时内存被回收。常见场景：Redis的列表结构常用于作为异步队列使用，线程1将需要延后处理的任务结构体序列化喂字符串放进list中，线程2从这个list中轮询取出数据进行处理。 右进左出：队列 123456789101112127.0.0.1:6379&gt; RPUSH books java golang python(integer) 3127.0.0.1:6379&gt; LLEN books(integer) 3127.0.0.1:6379&gt; LPOP books\"java\"127.0.0.1:6379&gt; LPOP books\"golang\"127.0.0.1:6379&gt; LPOP books\"python\"127.0.0.1:6379&gt; LPOP books(nil) 右进右出：栈 12345678910127.0.0.1:6379&gt; RPUSH books java golang python(integer) 3127.0.0.1:6379&gt; RPOP books\"python\"127.0.0.1:6379&gt; RPOP books\"golang\"127.0.0.1:6379&gt; RPOP books\"java\"127.0.0.1:6379&gt; RPOP books(nil) set（集合）Redis的set相当于Java中的HashSet，它存储的键值对是无序且唯一的；内部实现相当于一个特殊的Hash，一个所有value都为NULL的特殊Hash，当set中的最后一个元素被移除后，数据结构会自动删除，内存被回收。 123456789101112131415161718127.0.0.1:6379&gt; SADD books java(integer) 1127.0.0.1:6379&gt; SADD books java(integer) 0 # 这里重复插入失败，证明Set结构元素是唯一的127.0.0.1:6379&gt; SADD books golang python # 批量add(integer) 2127.0.0.1:6379&gt; SMEMBERS books # 结果元素顺序跟插入时不一致，证明Set内元素是无序的1) \"python\"2) \"java\"3) \"golang\"127.0.0.1:6379&gt; SISMEMBER books java # 查询某个元素是否存在，相当于contains(element)(integer) 1127.0.0.1:6379&gt; SISMEMBER books c++(integer) 0127.0.0.1:6379&gt; SCARD books # 获取集合长度，相当于count()(integer) 3127.0.0.1:6379&gt; SPOP books # 弹出一个元素\"python\" hash（哈希） Redis中的hash相当于Java 1.8之前中的HashMap，它是无序字典在内部结构的实现上跟HashMap是一样的，都是数组+链表的二维结构；在第一维hash的数组位置碰撞时，就会使用链表将碰撞的元素串联起来。 hash结构可用于存储用户信息，不同于字符串需要一次性对整个对象序列化，hash结构可以对用户信息中的每个字段单独存储，这样方便我们在获取用户信息时进行部分获取，减少网络传输消耗。 hash的缺点是它的储存消耗要高于单个字符串结构，至于在实际应用中使用哪种结构，需要大家根据实际情况进行选择。 1234567891011121314151617181920212223127.0.0.1:6379&gt; HSET books java \"Thinking in Java\" # 在命令行中如果字符串包含空格，需要用引号括起来(integer) 1127.0.0.1:6379&gt; HSET books golang \"Concurrency in go\"(integer) 1127.0.0.1:6379&gt; HSET books python \"Python cookbook\"(integer) 1127.0.0.1:6379&gt; HGETALL books # entries()，key和value间隔出现1) \"java\"2) \"Thinking in Java\"3) \"golang\"4) \"Concurrency in go\"5) \"python\"6) \"Python cookbook\"127.0.0.1:6379&gt; HLEN books(integer) 3127.0.0.1:6379&gt; HGET books java\"Thinking in Java\"127.0.0.1:6379&gt; HSET books golang \"Learning go programming\"(integer) 0 # 因为是更新操作，所以这里返回0127.0.0.1:6379&gt; HGET books golang\"Learning go programming\"127.0.0.1:6379&gt; HMSET books java \"Effective java\" golang \"Modern golang programming\" python \"Learning python\" # 批量set操作OK zset（有序集合） Redis中的zset结构类似于Java中的SortedSet和HashMap的结合体，一方面它是一个set，保证了内部元素value的唯一性；另一方面，它可以给每个元素value赋予一个score，表示这个value的排序权重。 zset在实际应用中可以用来存储排行榜数据，value值存储用户名称或ID，score存储分数，我们可以按照按照分数正/反序对用户列表进行排序。 12345678910111213141516171819202122232425262728293031323334353637127.0.0.1:6379&gt; ZADD ranking 22.22 \"zhangsan\"(integer) 1127.0.0.1:6379&gt; ZADD ranking 33.33 \"lisi\"(integer) 1127.0.0.1:6379&gt; ZADD ranking 11.11 \"wangwu\"(integer) 1127.0.0.1:6379&gt; ZRANGE ranking 0 -1 # 按score正序列出，参数区间为排名范围1) \"wangwu\"2) \"zhangsan\"3) \"lisi\"127.0.0.1:6379&gt; ZREVRANGE ranking 0 -1 # 按score逆序列出，参数区间为排名范围1) \"lisi\"2) \"zhangsan\"3) \"wangwu\"127.0.0.1:6379&gt; ZCARD ranking # 等同于count()(integer) 3127.0.0.1:6379&gt; ZSCORE ranking zhangsan # 获取指定value的score值\"22.219999999999999\" # 内部score使用double类型存储，所以存储小数点精度问题127.0.0.1:6379&gt; ZRANK ranking \"zhangsan\" # 获取指定value的排名，从0开始(integer) 1127.0.0.1:6379&gt; ZRANK ranking \"wangwu\"(integer) 0127.0.0.1:6379&gt; ZRANK ranking \"lisi\"(integer) 2127.0.0.1:6379&gt; ZRANGEBYSCORE ranking 0 30 # 根据score区间列出zset元素1) \"wangwu\"2) \"zhangsan\"127.0.0.1:6379&gt; ZRANGEBYSCORE ranking -inf 30 withscores # inf为infinite缩写，-inf为负无穷，withscores参数表示将score一同列出1) \"wangwu\"2) \"11.109999999999999\"3) \"zhangsan\"4) \"22.219999999999999\"127.0.0.1:6379&gt; ZREM ranking \"zhangsan\" # 删除value(integer) 1127.0.0.1:6379&gt; ZRANGE ranking 0 -11) \"wangwu\"2) \"lisi\" 其他高级命令1. KEYS：全局遍历键KEYS pattern查找所有符合给定模式pattern的key；特殊符号用\\隔开；keys命令的速度非常快，但在一个大的数据库中使用它仍然可能造成性能问题，要尽量避免使用。 123456789101112131415127.0.0.1:6379&gt; MSET one 1 two 2 three 3 four 4 # 一次设置 4 个 keyOK127.0.0.1:6379&gt; KEYS *o*1) \"four\"2) \"two\"3) \"one\"127.0.0.1:6379&gt; KEYS t??1) \"two\"127.0.0.1:6379&gt; KEYS t[w]*1) \"two\"127.0.0.1:6379&gt; KEYS * # 匹配数据库内所有key1) \"four\"2) \"three\"3) \"two\"4) \"one\" 2. SCAN：增量/渐进式遍历键SCAN cursor [MATCH pattern] [COUNT count] cursor：游标，整型值。 MATCH pattern：正则表达式，对redis的所有key过滤，可选。需要注意的是， 对元素的模式匹配工作是在命令从数据集中取出元素之后， 向客户端返回元素之前的这段时间内进行的， 所以如果被迭代的数据集中只有少量元素和模式相匹配， 那么迭代命令或许会在多次执行中都不返回任何元素。 COUNT count：每次迭代遍历多少个key，输出结果的key个数不保证与等于count。 SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标cursor， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数cursor， 以此来延续之前的迭代过程。当 SCAN 命令的游标参数cursor被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。 以下是一个 SCAN 命令的迭代过程示例： 123456789101112131415161718192021222324127.0.0.1:6379&gt; scan 0 # 游标设置为01) \"17\" # 返回新的游标，作为下次迭代的cursor参数2) 1) \"key:12\" 2) \"key:8\" 3) \"key:4\" 4) \"key:14\" 5) \"key:16\" 6) \"key:17\" 7) \"key:15\" 8) \"key:10\" 9) \"key:3\" 10) \"key:7\" 11) \"key:1\"127.0.0.1:6379&gt; scan 17 # 上轮返回的游标1) \"0\" # 当迭代返回的游标值为0时，说明redis中的所有key已经遍历完成2) 1) \"key:5\" 2) \"key:18\" 3) \"key:0\" 4) \"key:2\" 5) \"key:19\" 6) \"key:13\" 7) \"key:6\" 8) \"key:9\" 9) \"key:11\" Redis存储键值对实际使用的是HashTable的数据结构 3. INFO：查看redis服务运行信息INFO [section]：通过给定可选的参数 section ，可以让命令只返回某一部分的信息。 server : 一般 Redis 服务器信息，包含以下域： redis_version : Redis 服务器版本 redis_git_sha1 : Git SHA1 redis_git_dirty : Git dirty flag os : Redis 服务器的宿主操作系统 arch_bits : 架构（32 或 64 位） multiplexing_api : Redis 所使用的事件处理机制 gcc_version : 编译 Redis 时所使用的 GCC 版本 process_id : 服务器进程的 PID run_id : Redis 服务器的随机标识符（用于 Sentinel 和集群） tcp_port : TCP/IP 监听端口 uptime_in_seconds : 自 Redis 服务器启动以来，经过的秒数 uptime_in_days : 自 Redis 服务器启动以来，经过的天数 lru_clock : 以分钟为单位进行自增的时钟，用于 LRU 管理 clients : 已连接客户端信息，包含以下域： connected_clients : 已连接客户端的数量（不包括通过从属服务器连接的客户端） client_longest_output_list : 当前连接的客户端当中，最长的输出列表 client_longest_input_buf : 当前连接的客户端当中，最大输入缓存 blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 memory : 内存信息，包含以下域： used_memory : 由 Redis 分配器分配的内存总量，以字节（byte）为单位 used_memory_human : 以人类可读的格式返回 Redis 分配的内存总量 used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。 used_memory_peak : Redis 的内存消耗峰值（以字节为单位） used_memory_peak_human : 以人类可读的格式返回 Redis 的内存消耗峰值 used_memory_lua : Lua 引擎所使用的内存大小（以字节为单位） mem_fragmentation_ratio : used_memory_rss 和 used_memory 之间的比率 mem_allocator : 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc 。 在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。Because Redis does not have control over how its allocations are mapped to memory pages, high used_memory_rss is often the result of a spike in memory usage. 当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。查看 used_memory_peak 的值可以验证这种情况是否发生。 persistence : RDB 和 AOF 的相关信息 stats : 一般统计信息 replication : 主/从复制信息 cpu : CPU 计算量统计信息 commandstats : Redis 命令统计信息 cluster : Redis 集群信息 keyspace : 数据库相关的统计信息 更多命令详解请参考 Redis命令参考 Redis 命令参考（新版）","categories":[{"name":"分布式框架","slug":"分布式框架","permalink":"https://kwilove.github.io/categories/分布式框架/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://kwilove.github.io/tags/Redis/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-05-23T07:40:03.194Z","updated":"2019-05-23T06:15:50.000Z","comments":true,"path":"2019/05/23/hello-world/","link":"","permalink":"https://kwilove.github.io/2019/05/23/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"开博纪念","slug":"Hello-World","date":"2019-03-20T11:08:00.000Z","updated":"2019-05-23T08:48:58.420Z","comments":true,"path":"2019/03/20/Hello-World/","link":"","permalink":"https://kwilove.github.io/2019/03/20/Hello-World/","excerpt":"","text":"终于成功搭建了自己的私人博客，以前都是在CSDN等平台上发布技术相关的文章，现在可以优先上传到这里后再同步到其他平台上。 简历上也能放上自己的网址了，咱也得慢慢将档次提升上来才行。 以后有空会陆续将在其他平台发布的原创文章迁移过来，敬请期待！！！","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://kwilove.github.io/categories/杂谈/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://kwilove.github.io/tags/杂谈/"}]}]}