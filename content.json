{"meta":{"title":"子敬的博客","subtitle":null,"description":"子敬的博客","author":"子敬","url":"https://kwilove.github.io","root":"/"},"pages":[],"posts":[{"title":"了解MySQL的explain命令","slug":"了解MySQL的explain命令","date":"2019-05-23T14:12:40.000Z","updated":"2019-05-24T04:14:22.810Z","comments":true,"path":"2019/05/23/了解MySQL的explain命令/","link":"","permalink":"https://kwilove.github.io/2019/05/23/了解MySQL的explain命令/","excerpt":"","text":"一. 预备知识阅读本文章前需要掌握MySQL索引的底层数据结构相关知识，可以查看我之前的文章了解。 索引前导列: 所谓前导列，就是联合索引的第一列或者从第一列开始连续多列的组合。比如通过语句CREATE INDEX table1_index ON table1 (x, y, z)创建索引，那么x、xy、xyz都是前导列，而yz，y，z这样的就不是。 覆盖索引: 覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据表，换句话说查询列要被所建的索引覆盖。 二. explain命令的作用 使用explain关键字可以模拟优化器执行SQL语句，知道MySQL是如何处理你的SQL语句的，从而分析你的查询语句的性能瓶颈。 在select语句前添加explain关键字，MySQL会在查询上设置一个标记，在执行查询时，会返回执行计划信息，而不是返回查询语句的执行结果；如果from子句中包含select语句，该子查询依然会被执行，并且子查询的结果会产生临时表。 三. explain讲解需要使用的表 Actor演员表 12345678910111213141516DROP TABLEIF EXISTS `actor`;CREATE TABLE `actor` ( `id` INT (11) NOT NULL, `name` VARCHAR (45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `actor` (`id`, `name`, `update_time`)VALUES (1,'a','2017-12-22 15:27:18'), (2,'b','2017-12-22 15:27:18'), (3,'c','2017-12-22 15:27:18'); film影片表 12345678910111213141516DROP TABLEIF EXISTS `film`;CREATE TABLE `film` ( `id` INT (11) NOT NULL AUTO_INCREMENT, `name` VARCHAR (10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `film` (`id`, `name`)VALUES (3, 'film0'), (1, 'film1'), (2, 'film2'); film_actor影片演员关联表 123456789101112131415161718DROP TABLEIF EXISTS `film_actor`;CREATE TABLE `film_actor` ( `id` INT (11) NOT NULL, `film_id` INT (11) NOT NULL, `actor_id` INT (11) NOT NULL, `remark` VARCHAR (255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_film_actor_id` (`film_id`, `actor_id`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`)VALUES (1, 1, 1), (2, 1, 2), (3, 2, 1); 举例讲解1mysql&gt; explain select * from actor;` id列 id列是select的序列号，id的个数等于SQL语句中select的个数，并且id列的顺序与select出现的顺序一一对应、 id的值越大，对应的select语句执行优先级越高，也就是越早执行；id相同则从上往下执行，id为NULL是最后执行。 MySQL中的select语句分为： 简单查询SIMPLE 复杂查询PRIMARY 简单子查询 派生表，指from语句中的子查询 union查询 简单子查询 1explain select (select 1 from actor limit 1) from film; from子句子查询 1explain select id from (select id from film) as der; 这条查询语句执行时产生了一张临时表der，外部select引用了这张临时表。 union查询 1explain select 1 union all select 1; union执行结果总是放在一个匿名临时表中，因为这种临时表不在SQL中出现，所以它的id是NULL。 select_type列select_type列表示对应的select是简单查询还是复杂查询，如果是复杂查询又是哪种复杂查询。 SIMPLE: 简单查询，不包含子查询和union查询 1explain select * from film where id = 2; PRIMARY: 复杂查询中最外层的select SUBQUERY: 包含在select中的子查询，不再from子句中 DERIVED: 包含在from子句中的子查询，MySQL会将结果存放在一个临时表中，也称为派生表 1explain select (select 1 from actor where id = 1) from (select * from film where id = 1) der; UNION: 在union语句中的第二个和后面的select UNION RESULT: 在union匿名临时表中查询的select 1explain select 1 union all select 1; table列 table列表示explain中的select语句正在访问哪张表。 当from子句中有子查询时，table列为&lt;derivenN&gt;格式，表示当前查询依赖id=N的查询，于是先执行id=N的查询。 当有union时，UNION RESULT的table列的值是&lt;union1,2&gt;，其中1和2表示参与union的select的id。 type列这一列表示查询语句是关联类型还是访问类型，查找数据行记录的大概范围。type列数值从最优到最差的排序是：1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL。 在日常的开发中，我们建议确保查询能达到range以上，最好达到ref。 NULL: MySQL能够在优化阶段分解查询语句，在执行阶段不用再访问表或索引。例如，在索引列中选取最小值，可以通过查找索引完成，并不需要在执行时访问数据表。从下面的执行计划结果能看到table列为NULL，说明这条查询语句并没有访问表，而是直接查找索引得出结果。 1explain select min(id) from film; const: 当我们使用primary key或unique key的所在列与常量进行等值比较时，可以猜到查询结果只能是0条记录或者1条记录，这个结果的记录数是一个可预见常量，因此使用const标识。 system: system是const的一种特例，如果数据表中只有一条记录的话，那么我们查询的结果也最多是一条记录，这时结果记录数也是一个可预见常量，因此用system标识。 1explain extended select * from (select * from film where id = 1) tmp; eq_ref: 当使用关联查询（join）时，如果在关联条件join on中使用的字段是primary key或unique key，就会被标识为eq_ref。 1explain select * from film_actor left join film on film_actor.film_id = film.id; 如上图中显示的第二行film表的查询记录，因为在join on条件中使用的film.id就是film表的primary key，所以film表的查询计划结果行的type列为eq_ref。 ref: 相比于eq_ref的区别是查询条件中使用的字段是普通索引，或者是联合索引的前导列，下面列出两种出现ref类型的场景： 简单select查询，name是普通索引。 1explain select * from film where name = \"film1\"; 关联selevt查询。 1explain select film_id from film left join film_actor on film.id = film_actor.film_id; idx_film_actor_id是包含film_id和actor_id字段的联合索引，关联查询中使用到了film_actor表联合索引idx_film_actor_id的前导列film_id。 range: 使用索引字段进行范围查找，通常是in()、between…and…、&gt;、&gt;=、&lt;、&lt;=等操作。 1explain select * from actor where id &gt; 1; index: 扫描索引，通常是比ALL快一些，index是从索引中读取数据，ALL从硬盘中读取， 1explain select * from film; 因为film表中所有字段都走了索引，所以MySQL通过扫描索引取到了数据，因此没有再扫描表。 ALL: 全表扫描，意味着MySQL需要从头到尾的查找需要的行，遇到这种情况通常都是需要增加索引进行优化。 1explain select * from actor; possible_keys列这一列显示MySQL分析查询语句时可能使用到的索引。如果该列显示NULL，表示不使用索引查询，在这种情况下，通常我们都需要检查where子句，通过创建适当的索引优化查询性能。 key列 这一列显示了MySQL真正执行查询语句时使用到的索引。如果查询操作没有使用索引，则该列为NULL； 通过explain分析查询语句时可能会出现possible_keys列有值，但key列为NULL的情况，原因是表中数据不多，虽然MySQL分析出可能使用哪些索引，但是实际执行时认为索引对本次查询没什么帮助，选择了全表查询。 如果想强制使用possible_keys列中分析出的索引，可以在查询中使用force index、反之强制不使用possible_keys列的索引需要使用ignore index。 key_len列 这一列显示查询时使用的索引的字节数总和，在使用到联合索引时能通过该值分析出使用到了索引中的那些字段。 key_len的计算规则： 字符串 char(n): n为字节长度 varchar(n): 需要2个字节用于存储字符串长度，在使用utf-8字符集时，长度计算公式是3n + 2 数值类型 tinyint: 1字节 smallint: 2字节 int: 4字节 bigint: 8字节 时间类型 date: 3字节 timestamp: 4字节 datatime: 8字节 如果字段允许为NULL，还需要1字节用于记录是否为NULL 索引的最大长度为768字节，当字符串过长时，MySQL会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 样例说明：在film_actor表中创建了一个联合索引idx_film_actor_id，它由film_id和actor_id两个int类型字段组成。 执行下面的语句并得到结果 1explain select * from film_actor where film_id = 2; 按照我们上面的计算规则每个int是4字节，结果中key_len=4说明使用了film_id列进行索引查询。 执行另一条语句并得到结果 1explain select * from film_actor where film_id = 2 and actor_id = 1; 结果中key_len=8，刚好是film_id和actor_id字节之和。 ref列这一列显示在key列中列出的每个索引分别和什么类型的操作数做判断。 const（常量） 1explain select * from film_actor where film_id = 2; where子句film_id = 2中film_id是联合索引的前导列，2是常量，因此ref=const。 字段名 1explain select film_actor.film_id from film left join film_actor on film.id = film_actor.film_id; 我们看图中第二行是film_actor表的结论，关联条件是film.id = film_actor.film_id，其中film_actor.film_id是联合索引前导列，film.id是关联表字段，因此ref=test.film.id（数据库.表名.字段名）， rows列这一列显示的是MySQL估计需要读取和检测的行数，注意这里不是结果集里的行数。 Extra列这一列显示额外信息，常见的值如下: Using index: 查询的所有列被索引覆盖，并且where筛选条件（如果有where子句）是索引的前导列，这种结果代表了查询性能高效，一般是使用了覆盖索引。 12-- film_id列是film_actor表中联合索引idx_film_actor_id的前导列 explain select film_id from film_actor where film_id = 1; Using where; Using index: 查询的列被索引覆盖，并且where的筛选条件是索引列之一，但不是前导列，这种情况无法直接通过索引查找方式查询出符合条件的数据。 1explain select film_id from film_actor where actor_id = 1; Using where: 查询的列未被索引全部覆盖，并且where子句的筛选条件也不是索引的前导列。 1explain select * from actor where name = 'a'; NULL: 查询的列未被索引覆盖，但是where筛选条件是索引的前导列。可以这么理解，where子句走了索引，但是需要select的数据列不能全部从索引中获取，需要通过索引回表查询。 1explain select * from film_actor where film_id = 1; Using index condition: 与Using where类似，查询的列未被索引全部覆盖，where筛选条件是索引的前导列而且是一个范围查找。 1explain select * from film_actor where film_id &gt; 1; Using temporary: MySQL需要创建一张临时表来处理查询，这种情况一般都是需要优化的，可以考虑索引优化。 我们可以通过分析actor表和film表的name列去重查询进行分析对比，如下: actor表去重查询name: 1explain select distinct name from actor; 因为actor表的name没有加索引，所以MySQL创建了张临时表后再做去重。 film表去重查询name: 1explain select distinct name from film; 因为film表的name建立了idx_name索引，所以查询时Extra列显示为Using index，没有创建临时表。 Using filesort: MySQL对查询结果集进行了外部排序，而不是按照索引次序从表里读取行数据。这种情况下MySQL会扫描所出所有符合条件的记录，并记录排序关键字和行指针，然后对关键字排序并按顺序检索出行信息，遇到这种情况需要考虑使用索引优化查询。 为了方便理解，我们列举两条查询语句对explain结果进行分析对比。 按name排序查询actor表 1explain select * from actor order by name; 按name排序查询film表 1explain select * from film order by name; 从上面的执行结果可以看出，按name排序查询actor表时Extra=Using filesort，也就是对查询结果集做了外部排序；但按name排序查询film表时Extra=Using index；相同类型的查询语句，只是查询的表不同，为什么Extra的值不同呢？原因就是film表的name列加了索引，看过我之前文章的朋友应该都知道MySQL索引是一种排好序的数据结构，因此按name排序查询film表数据实际上是按照索引的顺序查询数据的，不需要再进行外部排序。 Extra是一个很复杂的项，在这里没法全部说明，需要大家自己去了解。","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://kwilove.github.io/tags/MySQL/"}]},{"title":"Springboot加载自定义yml文件配置的方法","slug":"Springboot加载自定义yml文件配置的方法","date":"2019-05-23T14:10:06.000Z","updated":"2019-05-23T14:11:14.048Z","comments":true,"path":"2019/05/23/Springboot加载自定义yml文件配置的方法/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Springboot加载自定义yml文件配置的方法/","excerpt":"","text":"Springboot在1.5.x版本之后，去除了@ConfigurationProperties注解中的location参数，因此无法再通过这种方式加载自定义的yml配置文件了。 我在网上看到很多资料都是这么说明的，我也没去验证，先不管吧，总之我搜集资料后特意总结了以下三种解决方法，亲测有效。 首先先在resources目录下创建一个测试用的yml配置文件，内容如下： PS：注意yml文件中key: value的冒号后面是有一个空格的 12345system: user: name: zjhuang password: 123456 age: 25 一. @ConfigurationProperties + @PropertySource + @Value注解方式 配置参数类代码： 这种方法必须配置@ConfigurationProperties中的prefix前缀信息，否则无法获取到yml数据。 @PropertySource是为了告知springboot加载自定义的yml配置文件，springboot默认会自动加载application.yml文件，如果参数信息直接写在这个文件里，则不需要显式加载。 在@ConfigurationProperties中配置了prefix前缀信息的条件下，@Value指定yml配置文件中的参数项名称。 123456789101112131415161718192021import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;@Component@ConfigurationProperties(prefix = \"system.user\")@PropertySource(value = \"classpath:test.yml\")public class YamlProperties &#123; @Value(\"$&#123;name&#125;\") private String name; @Value(\"$&#123;password&#125;\") private String password; @Value(\"$&#123;age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 测试用例代码： 后面的两种方式也共用这个测试用例代码，下面不再列出。 123456789101112131415161718import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)public class TestYamlLoader &#123; @Autowired private YamlProperties yamlProperties; @Test public void test() &#123; System.out.println(yamlProperties.toString()); &#125;&#125; 输出结果：1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 二. 实现PropertySourceFactory接口 + @PropertySource + @Value方式 PropertySourceFactory实现类代码 12345678910111213141516171819202122232425import org.springframework.boot.env.PropertySourcesLoader;import org.springframework.core.env.PropertySource;import org.springframework.core.io.Resource;import org.springframework.core.io.support.EncodedResource;import org.springframework.core.io.support.PropertySourceFactory;import org.springframework.util.StringUtils;import java.io.IOException;public class YamlPropertySourceFactory implements PropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource encodedResource) throws IOException &#123; return name != null ? new PropertySourcesLoader().load(encodedResource.getResource(), name, null) : new PropertySourcesLoader().load( encodedResource.getResource(), getNameForResource(encodedResource.getResource()), null); &#125; private static String getNameForResource(Resource resource) &#123; String name = resource.getDescription(); if (!StringUtils.hasText(name)) &#123; name = resource.getClass().getSimpleName() + \"@\" + System.identityHashCode(resource); &#125; return name; &#125;&#125; 配置参数类代码 12345678910111213141516171819import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;@Component@PropertySource(value = \"classpath:test.yml\", factory = YamlPropertySourceFactory.class)public class YamlProperties &#123; @Value(\"$&#123;system.user.name&#125;\") private String name; @Value(\"$&#123;system.user.password&#125;\") private String password; @Value(\"$&#123;system.user.age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 跟第一种方法不同点在于： 1、放弃了@ConfigurationProperties注解，改为实现了PropertySourceFactory接口 2、@PropertySource注解定义了factory属性，值为上一步中PropertySourceFactory实现类的class 3、@Value注解中使用了参数在yml’文件中的全限定名 输出结果： 1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 三.使用YamlPropertiesFactoryBean + @Value方式 PropertySourcesPlaceholderConfigurer类代码 1234567891011121314151617import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.context.annotation.Bean;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.io.ClassPathResource;import org.springframework.stereotype.Component;@Componentpublic class PropertySourcesPlaceholderConfigurerBean &#123; @Bean public PropertySourcesPlaceholderConfigurer yaml() &#123; PropertySourcesPlaceholderConfigurer configurer = new PropertySourcesPlaceholderConfigurer(); YamlPropertiesFactoryBean yaml = new YamlPropertiesFactoryBean(); yaml.setResources(new ClassPathResource(\"test.yml\")); configurer.setProperties(yaml.getObject()); return configurer; &#125;&#125; 配置参数类代码 这第三种方法去掉了@PropertySource 注解，改为定义一个PropertySourcesPlaceholderConfigurer类型的@Bean来加载配置文件信息。 12345678910111213141516171819202122import org.springframework.beans.factory.annotation.Value;import org.springframework.beans.factory.config.YamlPropertiesFactoryBean;import org.springframework.context.annotation.Bean;import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;import org.springframework.core.io.ClassPathResource;import org.springframework.stereotype.Component;@Componentpublic class YamlProperties &#123; @Value(\"$&#123;system.user.name&#125;\") private String name; @Value(\"$&#123;system.user.password&#125;\") private String password; @Value(\"$&#123;system.user.age&#125;\") private int age; // Setter... // Getter... // toString...&#125; 输出结果： 1YamlProperties&#123;name=&apos;zjhuang&apos;, password=&apos;123456&apos;, age=25&#125; 以上就是springboot加载自定义yml配置信息的三种方法，大家按照自己喜好选择使用即可；第三种方法好像只能用于加载一个yml文件的情况，第一和第二种方法可以实现加载多个yml文件，@PropertySources的value参数是支持数组赋值的。 1@PropertySource(value = &#123;&quot;classpath:test1.yml&quot;, &quot;classpath:test2.yml&quot;&#125;) 另外需要提一点的是，不管是加载几个yml文件，@Value修饰的所有参数都必须在yml文件中定义齐全，yml缺少配置的话会抛出无法解析占位符的异常 1Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder &apos;age&apos; in value &quot;$&#123;age&#125;&quot;","categories":[{"name":"技巧","slug":"技巧","permalink":"https://kwilove.github.io/categories/技巧/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"https://kwilove.github.io/tags/Springboot/"}]},{"title":"Redis核心原理","slug":"Redis核心原理","date":"2019-05-23T14:07:38.000Z","updated":"2019-05-23T14:09:45.253Z","comments":true,"path":"2019/05/23/Redis核心原理/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Redis核心原理/","excerpt":"","text":"Redis的单线程和高性能 Redis单线程为什么还能那么快？ 因为它所有的数据都存储在内存中，所有的运算都是内存级别的运算。 单线程避免了线程间切换的性能损耗。 正因为redis是单线程的，所以要谨慎使用那些耗时指令，比如keys，否则会导致redis卡顿。 Redis在单线程模式下如何做到高效处理并发客户端连接？ Redis通过epoll（IO多路复用模型）实现将客户端连接信息和事件放入队列，然后由文件事件分派器依次分发给对应的事件处理器。 Nginxy也是采用IO多路复用模型解决了C10K（10K并发连接数）问题。 Redis的持久化Redis 提供了多种不同级别的持久化方式： RDB快照 RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。 在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。 你也可以通过调用 SAVE 或者 BGSAVE ， 手动让 Redis 进行数据集保存操作；比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集： 1save 60 1000 AOF持久化 AOF持久化会记录Redis服务器执行过的所有写操作指令，并在服务器启动时，通过重新执行这些指令来还原数据集， 参考 Redis持久化","categories":[{"name":"分布式框架","slug":"分布式框架","permalink":"https://kwilove.github.io/categories/分布式框架/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://kwilove.github.io/tags/Redis/"}]},{"title":"2019-05-23-Redis基础数据结构","slug":"Redis基础数据结构","date":"2019-05-23T09:33:23.000Z","updated":"2019-05-23T14:06:30.262Z","comments":true,"path":"2019/05/23/Redis基础数据结构/","link":"","permalink":"https://kwilove.github.io/2019/05/23/Redis基础数据结构/","excerpt":"","text":"Redis有5种基础数据结构：string字符串、list列表、set集合、hash哈希和zset有序集合。Redis的所有数据结构都是一个唯一的字符串类型key作为名称，然后通过这个key值获取相应的value，Redis中5种数据结构就是体现在value上的。 string（字符串）string字符串时Redis最简单的数据结构，它的使用非常广泛；常见场景：比如用于缓存用户信息，我们将用户信息结构体通过JSON序列化成字符串放进Redis中缓存，取用户信息时会经过一个反序列化。单个键值对操作 set、get： 1234567891011127.0.0.1:6379&gt; set desc \"today is 2019-01-26\"OK127.0.0.1:6379&gt; get desc\"today is 2019-01-26\"127.0.0.1:6379&gt; exists desc(integer) 1127.0.0.1:6379&gt; del desc(integer) 1127.0.0.1:6379&gt; get desc(nil)127.0.0.1:6379&gt; 批量键值对操作 mset、mget：可以批量对多个字符串进行读写，节省网络耗时开销 1234567891011121314127.0.0.1:6379&gt; set lang1 chineseOK127.0.0.1:6379&gt; set lang2 englishOK127.0.0.1:6379&gt; mget lang1 lang2 lang31) \"chinese\"2) \"english\"3) (nil)127.0.0.1:6379&gt; mset book1 java book2 c++ book3 pythonOK127.0.0.1:6379&gt; mget book1 book2 book31) \"java\"2) \"c++\"3) \"python\" 过期命令expire和setex，可以对key设置过期时间，到点后自动删除，这个功能经常用于设置缓存失效时间： expire key secordssecords为过期时间，单位时秒 123456789127.0.0.1:6379&gt; set city guangzhouOK127.0.0.1:6379&gt; get city\"guangzhou\"127.0.0.1:6379&gt; expire city 5(integer) 1# 等待5s过后127.0.0.1:6379&gt; get city(nil) setex key secords valuesecords为过期时间，单位时秒，等价于set + expire 1234567127.0.0.1:6379&gt; setex city 5 guangzhouOK127.0.0.1:6379&gt; get city\"guangzhou\"# 等待5s过后127.0.0.1:6379&gt; get city(nil) set的其他扩展命令 setnx key value当key不存在时执行set操作 12345678127.0.0.1:6379&gt; setnx num 001(integer) 1127.0.0.1:6379&gt; get num\"001\"127.0.0.1:6379&gt; setnx num 002(integer) 0 # 因为num已经存在，所以此处设置不成功127.0.0.1:6379&gt; get num\"001\" # num的值没有改变 原子计数：如果value值设置成一个整数，Redis还支持对它记性自增、自减操作，自增自减时有范围的，它的范围时signed long的最大最小值，超过这个范围Redis会报错。 123456789101112127.0.0.1:6379&gt; set age 25OK127.0.0.1:6379&gt; incr age(integer) 26127.0.0.1:6379&gt; incrby age 10(integer) 36127.0.0.1:6379&gt; incrby age -5(integer) 31127.0.0.1:6379&gt; set max 9223372036854775807OK127.0.0.1:6379&gt; incr max(error) ERR increment or decrement would overflow list（列表）Redis的list相当于Java中的LinkedList，它是一个链表结构而不是数组结构，因此它具备链表的优、缺点；优点：list的插入和删除操作效率高，时间复杂度喂O(1)；缺点：list的查询或索引定位比较慢，时间复杂度喂O(n)；此外，列表的特性就是先进先出，当list弹出最后一个元素之后该数据结构自动被删除，同时内存被回收。常见场景：Redis的列表结构常用于作为异步队列使用，线程1将需要延后处理的任务结构体序列化喂字符串放进list中，线程2从这个list中轮询取出数据进行处理。 右进左出：队列 123456789101112127.0.0.1:6379&gt; RPUSH books java golang python(integer) 3127.0.0.1:6379&gt; LLEN books(integer) 3127.0.0.1:6379&gt; LPOP books\"java\"127.0.0.1:6379&gt; LPOP books\"golang\"127.0.0.1:6379&gt; LPOP books\"python\"127.0.0.1:6379&gt; LPOP books(nil) 右进右出：栈 12345678910127.0.0.1:6379&gt; RPUSH books java golang python(integer) 3127.0.0.1:6379&gt; RPOP books\"python\"127.0.0.1:6379&gt; RPOP books\"golang\"127.0.0.1:6379&gt; RPOP books\"java\"127.0.0.1:6379&gt; RPOP books(nil) set（集合）Redis的set相当于Java中的HashSet，它存储的键值对是无序且唯一的；内部实现相当于一个特殊的Hash，一个所有value都为NULL的特殊Hash，当set中的最后一个元素被移除后，数据结构会自动删除，内存被回收。 123456789101112131415161718127.0.0.1:6379&gt; SADD books java(integer) 1127.0.0.1:6379&gt; SADD books java(integer) 0 # 这里重复插入失败，证明Set结构元素是唯一的127.0.0.1:6379&gt; SADD books golang python # 批量add(integer) 2127.0.0.1:6379&gt; SMEMBERS books # 结果元素顺序跟插入时不一致，证明Set内元素是无序的1) \"python\"2) \"java\"3) \"golang\"127.0.0.1:6379&gt; SISMEMBER books java # 查询某个元素是否存在，相当于contains(element)(integer) 1127.0.0.1:6379&gt; SISMEMBER books c++(integer) 0127.0.0.1:6379&gt; SCARD books # 获取集合长度，相当于count()(integer) 3127.0.0.1:6379&gt; SPOP books # 弹出一个元素\"python\" hash（哈希） Redis中的hash相当于Java 1.8之前中的HashMap，它是无序字典在内部结构的实现上跟HashMap是一样的，都是数组+链表的二维结构；在第一维hash的数组位置碰撞时，就会使用链表将碰撞的元素串联起来。 hash结构可用于存储用户信息，不同于字符串需要一次性对整个对象序列化，hash结构可以对用户信息中的每个字段单独存储，这样方便我们在获取用户信息时进行部分获取，减少网络传输消耗。 hash的缺点是它的储存消耗要高于单个字符串结构，至于在实际应用中使用哪种结构，需要大家根据实际情况进行选择。 1234567891011121314151617181920212223127.0.0.1:6379&gt; HSET books java \"Thinking in Java\" # 在命令行中如果字符串包含空格，需要用引号括起来(integer) 1127.0.0.1:6379&gt; HSET books golang \"Concurrency in go\"(integer) 1127.0.0.1:6379&gt; HSET books python \"Python cookbook\"(integer) 1127.0.0.1:6379&gt; HGETALL books # entries()，key和value间隔出现1) \"java\"2) \"Thinking in Java\"3) \"golang\"4) \"Concurrency in go\"5) \"python\"6) \"Python cookbook\"127.0.0.1:6379&gt; HLEN books(integer) 3127.0.0.1:6379&gt; HGET books java\"Thinking in Java\"127.0.0.1:6379&gt; HSET books golang \"Learning go programming\"(integer) 0 # 因为是更新操作，所以这里返回0127.0.0.1:6379&gt; HGET books golang\"Learning go programming\"127.0.0.1:6379&gt; HMSET books java \"Effective java\" golang \"Modern golang programming\" python \"Learning python\" # 批量set操作OK zset（有序集合） Redis中的zset结构类似于Java中的SortedSet和HashMap的结合体，一方面它是一个set，保证了内部元素value的唯一性；另一方面，它可以给每个元素value赋予一个score，表示这个value的排序权重。 zset在实际应用中可以用来存储排行榜数据，value值存储用户名称或ID，score存储分数，我们可以按照按照分数正/反序对用户列表进行排序。 12345678910111213141516171819202122232425262728293031323334353637127.0.0.1:6379&gt; ZADD ranking 22.22 \"zhangsan\"(integer) 1127.0.0.1:6379&gt; ZADD ranking 33.33 \"lisi\"(integer) 1127.0.0.1:6379&gt; ZADD ranking 11.11 \"wangwu\"(integer) 1127.0.0.1:6379&gt; ZRANGE ranking 0 -1 # 按score正序列出，参数区间为排名范围1) \"wangwu\"2) \"zhangsan\"3) \"lisi\"127.0.0.1:6379&gt; ZREVRANGE ranking 0 -1 # 按score逆序列出，参数区间为排名范围1) \"lisi\"2) \"zhangsan\"3) \"wangwu\"127.0.0.1:6379&gt; ZCARD ranking # 等同于count()(integer) 3127.0.0.1:6379&gt; ZSCORE ranking zhangsan # 获取指定value的score值\"22.219999999999999\" # 内部score使用double类型存储，所以存储小数点精度问题127.0.0.1:6379&gt; ZRANK ranking \"zhangsan\" # 获取指定value的排名，从0开始(integer) 1127.0.0.1:6379&gt; ZRANK ranking \"wangwu\"(integer) 0127.0.0.1:6379&gt; ZRANK ranking \"lisi\"(integer) 2127.0.0.1:6379&gt; ZRANGEBYSCORE ranking 0 30 # 根据score区间列出zset元素1) \"wangwu\"2) \"zhangsan\"127.0.0.1:6379&gt; ZRANGEBYSCORE ranking -inf 30 withscores # inf为infinite缩写，-inf为负无穷，withscores参数表示将score一同列出1) \"wangwu\"2) \"11.109999999999999\"3) \"zhangsan\"4) \"22.219999999999999\"127.0.0.1:6379&gt; ZREM ranking \"zhangsan\" # 删除value(integer) 1127.0.0.1:6379&gt; ZRANGE ranking 0 -11) \"wangwu\"2) \"lisi\" 其他高级命令1. KEYS：全局遍历键KEYS pattern查找所有符合给定模式pattern的key；特殊符号用\\隔开；keys命令的速度非常快，但在一个大的数据库中使用它仍然可能造成性能问题，要尽量避免使用。 123456789101112131415127.0.0.1:6379&gt; MSET one 1 two 2 three 3 four 4 # 一次设置 4 个 keyOK127.0.0.1:6379&gt; KEYS *o*1) \"four\"2) \"two\"3) \"one\"127.0.0.1:6379&gt; KEYS t??1) \"two\"127.0.0.1:6379&gt; KEYS t[w]*1) \"two\"127.0.0.1:6379&gt; KEYS * # 匹配数据库内所有key1) \"four\"2) \"three\"3) \"two\"4) \"one\" 2. SCAN：增量/渐进式遍历键SCAN cursor [MATCH pattern] [COUNT count] cursor：游标，整型值。 MATCH pattern：正则表达式，对redis的所有key过滤，可选。需要注意的是， 对元素的模式匹配工作是在命令从数据集中取出元素之后， 向客户端返回元素之前的这段时间内进行的， 所以如果被迭代的数据集中只有少量元素和模式相匹配， 那么迭代命令或许会在多次执行中都不返回任何元素。 COUNT count：每次迭代遍历多少个key，输出结果的key个数不保证与等于count。 SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标cursor， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数cursor， 以此来延续之前的迭代过程。当 SCAN 命令的游标参数cursor被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。 以下是一个 SCAN 命令的迭代过程示例： 123456789101112131415161718192021222324127.0.0.1:6379&gt; scan 0 # 游标设置为01) \"17\" # 返回新的游标，作为下次迭代的cursor参数2) 1) \"key:12\" 2) \"key:8\" 3) \"key:4\" 4) \"key:14\" 5) \"key:16\" 6) \"key:17\" 7) \"key:15\" 8) \"key:10\" 9) \"key:3\" 10) \"key:7\" 11) \"key:1\"127.0.0.1:6379&gt; scan 17 # 上轮返回的游标1) \"0\" # 当迭代返回的游标值为0时，说明redis中的所有key已经遍历完成2) 1) \"key:5\" 2) \"key:18\" 3) \"key:0\" 4) \"key:2\" 5) \"key:19\" 6) \"key:13\" 7) \"key:6\" 8) \"key:9\" 9) \"key:11\" Redis存储键值对实际使用的是HashTable的数据结构 3. INFO：查看redis服务运行信息INFO [section]：通过给定可选的参数 section ，可以让命令只返回某一部分的信息。 server : 一般 Redis 服务器信息，包含以下域： redis_version : Redis 服务器版本 redis_git_sha1 : Git SHA1 redis_git_dirty : Git dirty flag os : Redis 服务器的宿主操作系统 arch_bits : 架构（32 或 64 位） multiplexing_api : Redis 所使用的事件处理机制 gcc_version : 编译 Redis 时所使用的 GCC 版本 process_id : 服务器进程的 PID run_id : Redis 服务器的随机标识符（用于 Sentinel 和集群） tcp_port : TCP/IP 监听端口 uptime_in_seconds : 自 Redis 服务器启动以来，经过的秒数 uptime_in_days : 自 Redis 服务器启动以来，经过的天数 lru_clock : 以分钟为单位进行自增的时钟，用于 LRU 管理 clients : 已连接客户端信息，包含以下域： connected_clients : 已连接客户端的数量（不包括通过从属服务器连接的客户端） client_longest_output_list : 当前连接的客户端当中，最长的输出列表 client_longest_input_buf : 当前连接的客户端当中，最大输入缓存 blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 memory : 内存信息，包含以下域： used_memory : 由 Redis 分配器分配的内存总量，以字节（byte）为单位 used_memory_human : 以人类可读的格式返回 Redis 分配的内存总量 used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。 used_memory_peak : Redis 的内存消耗峰值（以字节为单位） used_memory_peak_human : 以人类可读的格式返回 Redis 的内存消耗峰值 used_memory_lua : Lua 引擎所使用的内存大小（以字节为单位） mem_fragmentation_ratio : used_memory_rss 和 used_memory 之间的比率 mem_allocator : 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc 。 在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。Because Redis does not have control over how its allocations are mapped to memory pages, high used_memory_rss is often the result of a spike in memory usage. 当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。查看 used_memory_peak 的值可以验证这种情况是否发生。 persistence : RDB 和 AOF 的相关信息 stats : 一般统计信息 replication : 主/从复制信息 cpu : CPU 计算量统计信息 commandstats : Redis 命令统计信息 cluster : Redis 集群信息 keyspace : 数据库相关的统计信息 更多命令详解请参考 Redis命令参考 Redis 命令参考（新版）","categories":[{"name":"分布式框架","slug":"分布式框架","permalink":"https://kwilove.github.io/categories/分布式框架/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://kwilove.github.io/tags/Redis/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-05-23T07:40:03.194Z","updated":"2019-05-23T06:15:50.000Z","comments":true,"path":"2019/05/23/hello-world/","link":"","permalink":"https://kwilove.github.io/2019/05/23/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Nginx性能参数调优","slug":"nginx-2019-04-12-Nginx性能参数调优","date":"2019-04-12T11:08:00.000Z","updated":"2019-05-23T05:14:22.227Z","comments":true,"path":"2019/04/12/nginx-2019-04-12-Nginx性能参数调优/","link":"","permalink":"https://kwilove.github.io/2019/04/12/nginx-2019-04-12-Nginx性能参数调优/","excerpt":"","text":"content{:toc} 1. worker_processes123语法:worker_processes number | auto;* number：Nginx进程最多可以产生的工作进程数量* auto： Nginx进程将自动检测 Nginx服务器实现并发处理服务的关键。每个worker进程都是单线程的进程，它们会调用各个模块以实现多种多样的功能。如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。例如，如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I/O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。 2. worker_connections12worker_connections number;Default: worker_connections 1024 每个worker进程的最大连接数，理论上每台nginx服务器的最大连接数为worker_processes * worker_connections。 3. worker_cpu_affinity1worker_cpu_affinity cpumask [cpumask……]; 绑定Nginx worker进程到指定的CPU内核。为什么要绑定worker进程到指定的CPU内核呢？假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。反之，如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。例如，如果有4核CPU，就可以进行如下配置：worker_processes 4;worker_cpu_affinity 1000 0100 0010 0001;注意 worker_cpu_affinity配置仅对Linux操作系统有效。 四核CPU，cpumask为1000 0100 0010 0001；八核CPU，cpumask为10000000 01000000 00100000 00010000 00001000 00000100 00000010 00000001，以此类推。 4. worker_priority12worker_priority nice;Default: worker_priority 0; Nginx worker进程优先级设置。优先级由静态优先级和内核根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。nice值是进程的静态优先级，它的取值范围是–20～+19，–20是最高优先级，+19是最低优先级。因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小 5. worker_rlimit_nofile12worker_rlimit_nofile limit;Default: 空 Nginx worker进程可以打开的最大句柄描述符个数。更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比ulimit -a更多的文件，所以把这个值设高，这样nginx就不会有too many open files问题了。 6. open_file_cache1open_file_cache max=65535 inactive=20s; 为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 7. accept_mutext12accept_mutex [on|off];Default: accept_mutext on; 是否打开accept锁。accept_mutex是Nginx的负载均衡锁，当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会，accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。 8. accept_mutex_delay12accept_mutex_delay Nms;Default: accept_mutex_delay 500ms; 使用accept锁后到真正建立连接之间的延迟时间。在启用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个accept锁不是阻塞锁，如果取不到会立刻返回。如果只有一个worker进程试图取锁而没有取到，他至少要等待accept_mutex_delay定义的时间才能再次试图取锁。","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"Nginx实用案例","slug":"nginx-2019-04-10-Nginx实用案例","date":"2019-04-10T11:08:00.000Z","updated":"2019-05-23T05:14:22.226Z","comments":true,"path":"2019/04/10/nginx-2019-04-10-Nginx实用案例/","link":"","permalink":"https://kwilove.github.io/2019/04/10/nginx-2019-04-10-Nginx实用案例/","excerpt":"","text":"content{:toc} 一. 动静分离 基于目录实现 1234567891011server &#123; listen 80; server_name *.abc.com; root /usr/www/abc; location / &#123; index index.html; &#125; location /static &#123; alias /usr/www/static; &#125;&#125; 基于正则实现 123location ~* \\.(gif|jpg|png|css|js)$ &#123; root /usr/www/static;&#125; 二. 防盗链Nginx的ngx_http_referer_module模块通常用于阻止来源非法的请求，但是伪装Referer头信息是非常简单的，所以该模块只是能阻止大部分非法请求，另外，由于受浏览器、防火墙或代理服务器处理的影响，有些合法请求是不携带Referer头信息或者Referer的值被删除，这种情况也应该要考虑在内。详情请参考官方文档。 在server或location配置块内加入以下指令：123456789# none:允许请求头缺少Referer参数的请求访问资源。# blocked:允许请求头中Referer参数值为空的请求访问资源。# *.abc.com:设置来源白名单，只允许来自域名*.abc.com的请求访问资源，多个值使用空格分割。valid_referers none blocked *.abc.com;# 如果请求不满足上述条件，$invalid_referer将被设置成\"1\"。if ($invalid_referer) &#123; return 403;&#125; 三. 下载限速 limit_rate rate;限制向客户端传输响应的速率。rate以字节每秒为单位指定。默认值为0表示关闭速率限制。限制是根据每个请求设置的，因此，如果客户端同时打开两个连接，那么总速率将是rate值的两倍。也可以通过设置$limit_rate变量实现限速，这种方式对于需要根据某些条件对速率进行限制的情况是很有用的。 limit_rate_after size;设置初始总量，在向客户端传输的响应数据总大小超出limit_rate_after设置的数值之后才会进行速率限制，未超出则limit_rate不生效。 1234location /download &#123; limit_rate 1m; limit_rate_after 30m;&#125; 四. IP黑名单step1. 创建黑名单文件:echo ‘deny 192.168.0.111;’ &gt;&gt; black.ip step2. 在http配置块中引入黑名单文件:1include black.ip; 五. 针对指定客户端请求输出debug级别日志语法:debug_connection [IP | CIDR]作用:这个配置项实际上是属于事件类，所以要放在events配置块中才有效。1234events &#123; debug_connection 192.168.0.111; debug_connection 192.168.0.0/24;&#125; 参考 Nginx之ngx_http_referer_module模块 Nginx之ngx_http_core_module模块#limit_rate参数","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"Nginx之ngx_http_rewrite_module模块","slug":"nginx-2019-04-08-Nginx之ngx-http-rewrite-module模块","date":"2019-04-08T11:08:00.000Z","updated":"2019-05-23T05:14:22.225Z","comments":true,"path":"2019/04/08/nginx-2019-04-08-Nginx之ngx-http-rewrite-module模块/","link":"","permalink":"https://kwilove.github.io/2019/04/08/nginx-2019-04-08-Nginx之ngx-http-rewrite-module模块/","excerpt":"","text":"content{:toc} 1. ngx_http_rewrite_module模块介绍 Nginx的ngx_http_rewrite_module模块用于通过PCRE正则表达式修改请求URI，返回重定向，和按条件选择符合的配置信息。 本篇文章根据官方文档进行翻译，限于个人水平，如有错误，欢迎指正。 break、if、return、rewrite和set指令的处理顺序 如果在server级别下配置了rewrite指令，它会在location指令之前执行。 匹配location。 执行匹配到的location中配置的rewrite重写规则，重写URI。 在URI重写后，使用新的URI循环执行第1、2、3步骤。 循环最多重复10次，超过后Nginx将返回500 error。 2. break指令 语法：break默认值：none作用域：server、location、if作用：停止执行当前虚拟主机（server{}）的后续rewrite指令。示例： 1234if ($slow) &#123; limit_rate 10k; break;&#125; 3. if指令 语法：if(condition) {…}默认：none作用域：server、location作用：判断condition条件的真假，如果为true，定义在大括号内的模块指令将被执行，请求将按照if指令内的配置处理；if指令内的配置会继承以前的配置级别。 condition表达式： 一个变量名称；如果一个变量的值是空字符串””或”0”，则表示false；在1.0.1版本之前，任何以”0”开头的字符串都被认为是false； 使用=和!=运算符比较变量和字符串； 使用~*和~运算符对变量进行正则表达式匹配： ~区分大小写； ~*不区分大小写，例如firefox匹配到FireFox； !~*和!~表示否定，表示不匹配。 使用括号()捕获的正则表达式，后续可以通过$1-$9使用； 123正则表达式： /users/(.*)$请求uri： /users/get/100$1的值： get/100 如果正则表达式包含}或;字符，则整个表达式应该用单引号或双引号括起来。 使用-f和!-f运算符检测一个文件是否存在； 使用-d和!-d运算符检测一个目录是否存在； 使用-e和!-e运算符检测一个文件/目录/符号链接是否存在； 使用-x和!-x运算符检测一个文件是否可执行。 示例： 1234567891011121314151617181920if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* \"id=([^;] +)(?:;|$)\" ) &#123; set $id $1;&#125;if ($request_method = POST ) &#123; return 405;&#125;if (!-f $request_filename) &#123; break; proxy_pass http://127.0.0.1;&#125;if ($slow) &#123; limit_rate 10k;&#125;# 内置变量$invalid_referer的值由valid_referers指令提供。if ($invalid_referer) &#123; return 403;&#125; 4. return指令 语法：return code [text]; return code URL; return URL;默认值：none作用域：server、location、if作用： 此指令结束规则的执行，并返回状态码给客户端，在0.7.51的版本之前只能返回以下状态码：204、400、402-406、408、410、411、413、416和500-504； 此外，可以通过返回非标准代码444，在不发送相应头的情况下关闭一个连接； 从0.8.42版本起，return指令可以指定重定向URL（针对状态码301、302、303、307），或者指定响应体text（针对其他状态码）； 响应体文本和重定向URL可以包含变量； 有一种特殊情况，可以将重定向URL指定为当前服务器的本地URI，在这种情况下，将根据请求协议($scheme)、server_name_in_redirect指令和port_in_redirect指令形成完整的重定向URL。 此外，带有302状态码的临时重定向URL可以被指定为唯一参数，这个参数应该以”http://“、”https://“或者”$scheme”字符串开头，可以包含变量； 123456# 监听www.abc.com/abc.com的80端口，将http请求转为到https请求。server &#123; listen 80; server_name www.abc.cn abc.cn; return 301 https://$server_name$request_uri;&#125; 状态码307直到版本1.1.16和1.0.13才被视为重定向。 状态码308直到1.13.0版本才被视为重定向。 5. rewrite指令 语法：rewrite regex replacement [flag];默认：none作用域：server、location、if作用： 如果指定的正则表达式能匹配请求URI，URI将被更改为指定的replacement字符串； rewrite指令将按照它们在配置文件中出现的位置顺序执行； 可以使用标志flag终止对指令的进一步处理，flag可以选择下列值之一； last 停止处理当前的ngx_http_rewrite_module指令集，并开始搜索一个能匹配更改后URI的location规则; break 与break指令一样，停止处理当前的ngx_http_rewrite_module指令集; redirect 返回一个带有302状态码的临时重定向，如果替换字符串不以”http://“、”https://“或”$scheme”开头，则可以使用这个值; permanent 返回带有301状态码的永久重定向。 如果替换字符串以”http://“、”https://“或”$scheme”开头，处理工作将停止，并将重定向的结果返回给客户端。 完整的重定向URL将根据请求协议($scheme)、server_name_in_redirect指令和port_in_redirect指令形成 123456789101112131415161718server &#123; ... rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra last; return 403; ...&#125;# 如果上面这个例子的指令放在`location /download/ &#123;...&#125;`内部，则需要将`last`标志换成`break`，否则nginx将会进行10次循环，最终返回500错误，修改如下。server &#123; ... location /download/ &#123; rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra break; return 403; &#125; ...&#125; 注意重写表达式只对相对路径有效，如果你想匹配主机名，你应该使用if条件语句，如下： 12345if ($host ~* www\\.(.*)) &#123; set $host_without_www $1; # $1 contains '/foo', not 'www.mydomain.com/foo' rewrite ^(.*)$ http://$host_without_www$1 permanent; &#125; 如果替换字符串包含新的请求参数，则将在新参数之后追加先前的请求参数。如果不希望这样，在替换字符串的末尾加上问号可以避免最新就请求参数，例如: 1rewrite ^/users/(.*)$ /show?user=$1? last; 如果正则表达式包含}或;字符，则整个表达式需要用单引号或双引号括起来。 6. rewrite_log指令 语法：rewrite_log on | off;默认：rewrite_log off;作用域：http, server, location, if作用：开启或关闭将ngx_http_rewrite_module模块指令处理结果的notice级别日志写入error.log文件中。 7. set指令 语法：set $variable value;默认：none作用域：server, location, if作用：为指定的变量设置一个值。该值可以包含文本、变量及其组合。 8. uninitialized_variable_warn指令 语法：uninitialized_variable_warn on | off;默认：uninitialized_variable_warn on;作用域：http, server, location, if作用：控制是否记录未初始化变量的警告信息。","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"Nginx负载均衡","slug":"nginx-2019-04-06-Nginx负载均衡","date":"2019-04-06T11:08:00.000Z","updated":"2019-05-23T05:14:22.224Z","comments":true,"path":"2019/04/06/nginx-2019-04-06-Nginx负载均衡/","link":"","permalink":"https://kwilove.github.io/2019/04/06/nginx-2019-04-06-Nginx负载均衡/","excerpt":"","text":"content{:toc} 一. 介绍这篇文章是介绍如何配置nginx的负载均衡以及几种负载均衡策略的用法，其实实现起来非常之简单，使用upstream块就能做到，不多说，我们直接上配置。 二. 负载均衡配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; # 设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定负载均衡的服务器列表 upstream backend1 &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.8.101:8080 weight=5; server 192.168.8.102:8080 weight=1; server 192.168.8.103:8080 weight=6; &#125; upstream backend2 &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.8.201:8080 weight=1; server 192.168.8.202:8080 weight=6; &#125; # 设定虚拟主机配置 server &#123; # 侦听80端口 listen 80; # 定义使用什么虚拟主机地址访问，可以填写多个值，使用空格分开，支持通配符和正则 server_name localhost; # 定义服务器的默认网站根目录位置，支持相对路径和绝对路径，此处html为相对路径，等同于$&#123;NGINX_HOME&#125;/html root html; # 定义首页索引文件的名称 index index.php index.html index.htm; # 设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log logs/quancha.error.log; #对以/static/开始的uri请求进行负载均衡 location ^~ /static/ &#123; #请求转向backend1定义的服务器列表 proxy_pass http://backend1; # 省略一些反向代理的配置 # ... &#125; # 对通用请求进行负载均衡 location / &#123; #请求转向backend2定义的服务器列表 proxy_pass http:/backend2; # 省略一些反向代理的配置 # ... &#125; &#125;&#125; 三. 负载均衡策略Nginx的负载均衡策略可以分为两大类:内置策略和扩展策略。在最新的Nginx版本中，常见的几种内置策略包含轮询、加权轮询weight、ip_hash、least_conn、least_time和普通hash和一致性hash，在默认的情况下这两种策略是编译进nginx内核中的，只需在nginx配置中指明即可启用。扩展策略有很多类，fair、url_hash。 轮询（默认）每个请求按顺序逐一分配到不同的后端服务器处理，如果服务器down掉，会自动剔除。 加权轮询weight指定轮询到的几率，访问比率和weight成正比，这种策略适用于后端服务器性能不均的场景，为性能更优的服务器设置更大的权重weight。 ip_hash根据每个请求的来源IP信息做hash处理后的结果分配服务器，这种策略可以将同一个IP来源的请求固定分配到同一台机器，可以用于解决session一致性问题。 1234567upstream backend &#123; # 可选项：ip_hash、least_conn、least_time... ip_hash; server 192.168.8.101:8080; server 192.168.8.102:8080; # ...&#125; least_conn将请求分配给活跃连接数最小的后端服务器，如果存在多个这样的节点，将按照加权轮询算法处理。 least_time将请求分配给平均响应时间最短和活跃连接数最小的后端服务器，如果存在多个这样的节点，将按照加权轮询算法处理。 普通hash和一致性hash语法:hash key [consistent]; 普通hash不指定consistent参数，采用普通hash，使用这种策略时，nginx会基于key值通过内部算法计算出客户机-服务器映射表，key可以包含文本、变量及其组合。注意，从服务器列表中添加或删除节点可能会导致大多数的keys值需要重新映射到不同的服务器。 1234567upstream backend &#123; # key设为$request_uri，将按照请求uri映射到具体某个服务器。 hash $request_uri; server 192.168.8.101:8080; server 192.168.8.102:8080; # ...&#125; 一致性hash如果指定了consistent参数，则采用ketama一致哈希算法（点击这里了解）。该算法确保了在从服务器列表中添加或删除节点时，只有少数keys需要重新映射到不同的服务器。这有助于为缓存服务器实现更高的缓存命中率。 fair根据每个后端服务器的响应时间判断负载情况，将请求分配到响应时间最短的服务器，也就是负载最小的节点。 url_hash通过将请求url做hash处理后的结果分配后端服务器，这种策略可以将相同的url分配到同一个服务器处理，经常用于做静态资源缓存。 四. upstream相关参数 server:负载均衡的后端服务器地址加端口号。 123456 upstream backend &#123; # server host:port server 192.168.8.101:8080; server 192.168.8.102:8080; # ...&#125; weight:设置服务器权重，默认值为1。 123456 upstream backend &#123; # server host:port server 192.168.8.101:8080 weight=5; server 192.168.8.102:8080 weight=10; # ...&#125; max_fails:判断后端服务器访问失败多少次后认为已经down掉，主动剔除。 123456 upstream backend &#123; # server host:port server 192.168.8.101:8080 max_fails=3; server 192.168.8.102:8080 max_fails=5; # ...&#125; fail_timeout:后端服务器被剔除后重新探测的时间。 123456 upstream backend &#123; # server host:port server 192.168.8.101:8080 max_fails=3 fail_timeout=30s; server 192.168.8.102:8080 max_fails=5; # ...&#125; backup:将服务器标记为备份服务器。当主服务器不可用时，它将会处理请求。 12345678 upstream backend &#123; # server host:port server 192.168.8.101:8080; server 192.168.8.102:8080; # 在其他主服务器可用时，192.168.8.103服务器不参与负载均衡。 server 192.168.8.103:8080 backup; # ...&#125; max_conns:允许后端服务器的最大并发连接数，默认值为0表示没有限制。 如果启用了idle keepalive connections、多个工作进程（multiple worker）和共享内存（shared memory），代理服务器活跃和空闲连接的总数可能会超出max_conns的值。 slow_start:当节点恢复，不立即加入，而是等待slow_start后加入服务对列。 The parameter cannot be used along with the hash and ip_hash load balancing methods.该参数不能在hash和ip_hash策略下使用。 down:将服务器标记为永久不可用。 12345678 upstream backend &#123; # server host:port server 192.168.8.101:8080; server 192.168.8.102:8080; # 192.168.8.103服务器不参与负载均衡。 server 192.168.8.103:8080 down; # ...&#125; 参考 解析 Nginx 负载均衡策略这篇文章写的非常好，着重分析了内置策略的源码，并且对各种负载均衡策略做了对比测试，很有参考价值。 官方文档:Module ngx_http_upstream_module","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"Nginx反向代理","slug":"nginx-2019-04-04-Nginx反向代理","date":"2019-04-04T11:08:00.000Z","updated":"2019-05-23T05:14:22.221Z","comments":true,"path":"2019/04/04/nginx-2019-04-04-Nginx反向代理/","link":"","permalink":"https://kwilove.github.io/2019/04/04/nginx-2019-04-04-Nginx反向代理/","excerpt":"","text":"content{:toc} 一. 介绍反向代理是Ngxin非常重要的一项功能，那么什么是反向代理呢？以及我们什么时候会用到反向代理？ 反向代理：外部客户端通过网关访问网关所在内部网络中服务器上的内容，此时网关起到了反向代理的作用， 我们平常通过浏览器访问远程Web服务器基本都是通过反向代理访问内容的。Nginx的反向代理功能可以通过在配置文件的http-&gt;server-&gt;location块中设置proxy_pass指令帮助我们完成。 二. 准备工作在配置nginx之前，我们先在本地启动一个应用程序，然后确保能正常访问到服务 http://127.0.0.1:8080/ 三. nginx.conf 配置为了简洁，我这里只列出核心配置，需要完整配置的可以参考我的上一篇文章Nginx核心配置讲解与实践 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768http &#123; # 设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; # 设定虚拟主机配置 server &#123; # 侦听80端口 listen 80; # 定义使用什么虚拟主机地址访问，可以填写多个值，使用空格分开，支持通配符和正则 server_name localhost; # 定义服务器的默认网站根目录位置，支持相对路径和绝对路径，此处html为相对路径，等同于$&#123;NGINX_HOME&#125;/html root html; # 定义首页索引文件的名称 index index.php index.html index.htm; # 设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log logs/quancha.error.log; # 默认请求 location / &#123; # 请求转发到目标服务地址 proxy_pass http://127.0.0.1:8080/; # 以下是一些反向代理的配置参数，可删除 proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， client_body_buffer_size 128k; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers * 2） proxy_busy_buffers_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; # 配置静态资源，$&#123;APP_HOME&#125;为应用程序根目录 location /static &#123; alias $&#123;APP_HOME&#125;/static; &#125; &#125;&#125; 上述配置nginx监听了localhost的80端口，并且将该端口接收到的所有请求（location /匹配任意uri）转发给http://127.0.0.1:8080/，由后者负责处理并返回结果给请求发起终端，由此实现了反向代理的功能。最后我们访问localhost（在未显式声明端口号时默认使用80端口） 四. 自定义vhosts在上面的步骤中，我们是直接将配置写入nginx.conf文件，但是在实际工作中，我们建议能自己建立vhost文件。 前面是通过IP地址访问，下面我们改为使用域名访问；域名需要事先指向我们Nginx服务器，我们可以通过在hosts文件中添加映射记录实现域名和IP地址的映射： hosts文件路径 Windows：C:\\Windows\\System32\\drivers\\etc\\hosts Linux：/etc/hosts 添加hosts记录127.0.0.1 www.abc.com 首先我们现在nginx.conf同目录下新建一个vhosts目录（当然您也可以不建立，后续的include引入路径差异而已） 在vhosts目录下创建一个www.abc.com.conf（域名.conf）文件，文件名可自由定义，一般我会用域名作为文件名；文件内容如下: 12345678910111213141516171819202122232425262728293031# 设定虚拟主机配置server &#123; # 侦听80端口 listen 80; # 这里我改为使用域名访问，注意：域名需要指向当前Nginx服务器 server_name www.abc.com; # 定义服务器的默认网站根目录位置，支持相对路径和绝对路径，此处html为相对路径，等同于$&#123;NGINX_HOME&#125;/html root html; # 定义首页索引文件的名称 index index.php index.html index.htm; # 设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log logs/quancha.error.log; # 默认请求 location / &#123; # 请求转发到目标服务地址 proxy_pass http://127.0.0.1:8080/; # 这里省略其它反向代理配置项... &#125; # 配置静态资源，$&#123;APP_HOME&#125;为应用程序根目录 location /static &#123; alias $&#123;APP_HOME&#125;/static; &#125;&#125; 再来使用http://www.abc.com/访问下","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"数据库事务特性及隔离级别","slug":"数据库事务特性及隔离级别","date":"2019-04-03T14:11:39.000Z","updated":"2019-05-24T07:08:36.849Z","comments":true,"path":"2019/04/03/数据库事务特性及隔离级别/","link":"","permalink":"https://kwilove.github.io/2019/04/03/数据库事务特性及隔离级别/","excerpt":"","text":"事务的四个基本特性（ACID） 1. 原子性（Atomicity）： 同一个事务所包含的所有操作，要么全做，要么全不做，任何一项操作的失败都会导致整个事务的失败； 2. 一致性（Consistency）： 当事务结束后，系统在执行事务操作前后的状态是一致的； 这里举个例子来说，比如A（余额300元）转账给B（余额200元），在一个事务中，无论A转了多少钱，转了几次，在事务完成后，A和B的总金额还是500元； 3. 隔离性（Durability） 并发执行的多个事务操作是相互隔离，互不影响的，并且无法看到其他事务的中间状态； 数据库提供了多种隔离级别，这块后面会说道。 4. 持久性 事务完成后所做的所有改动都会被持久化，永久生效，即使数据库发生了灾难性故障也不会对已经完成的事务结果造成影响。 事务隔离级别 在高并发情况下，要完成保证事务ACID特性是十分困难的，除非把所有的事务串行化执行，但是因此造成的影响将是系统性能大大降低。在实际开发中很多业务对事务的要求是不一样的，因此数据库设计了四种隔离级别供用户基于业务进行选择。 隔离级别 脏读（Dirty Read） 不可重复读（Non-repeatable Read） 幻读（Phantom Read） 读未提交（Read uncommitted） 可能 可能 可能 读已提交（Read committed） 不可能 可能 可能 可重复读（Repeatable read） 不可能 不可能 可能 串行化（Serializable） 不可能 不可能 不可能 脏读：一个事务读取到另一个事务还未提交的数据。 不可重复读：在同一个事务中，前后两次执行相同的查询操作，出现返回的结果不一致的情况，换言之就是后一次查询操作能够读取到其他事务已提交的更新数据；“可重复读” 与之相反，是指在同一个事务中，前后两次查询操作读取到的结果一致，其他事务提交的更新数据不会对本事务造成影响。 幻读：查询表中一条记录，如果发现不存在就插入一条，并发情况下，发现表中出现两条相同记录，这就是幻读。 数据库默认的隔离级别 Oracle默认隔离级别是Read committed； MySQL默认是Repeatable read，另外在MySQL中执行一条查询语句默认是一个独立事务操作，所以看上去效果跟Read committed一样； 查看MySQL隔离级别信息： 1select @@tx_isolation; 设置MySQL隔离级别： 1set [global|session] transaction isolation level 隔离级别名称; 或 1set tx_isolation=’隔离级别名称;’ 可选参数： READ-UNCOMMITTED READ-COMMITTED REPEATABLE-READ SERIALIZABLE","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"数据库事务","slug":"数据库事务","permalink":"https://kwilove.github.io/tags/数据库事务/"}]},{"title":"Nginx核心配置讲解与实践","slug":"nginx-2019-03-28-Nginx核心配置讲解与实践","date":"2019-03-28T11:08:00.000Z","updated":"2019-05-24T03:04:18.847Z","comments":true,"path":"2019/03/28/nginx-2019-03-28-Nginx核心配置讲解与实践/","link":"","permalink":"https://kwilove.github.io/2019/03/28/nginx-2019-03-28-Nginx核心配置讲解与实践/","excerpt":"","text":"content{:toc} 一. 了解Nginx架构1. Nginx架构图 2. 架构说明 Nginx在启动时，会创建两种类型的进程，一个主进程Master，和一个或多个工作进程Worker（PS：Windows操作系统下只创建一个Worker）；其中主进程并不处理网络请求，它只负责工作进程的调度工作，如上图中显示的三项：加载配置、启动工作进程和非停升级。 Nginx服务器实际处理网络请求和做出响应的是工作进程Worker，在类Unix操作系统中允许配置启动多个Worker，并且每个Worker能同时处理上千个网络请求。 Nginx的模块化设计：工作进程Worker包含了核心模块和功能性模块，核心模块负责一个运行循环（run-loop），在网络请求处理过程的不同阶段的功能模块的执行工作，如：网络读写、存储读写、内容传输、外出过滤以及将请求发往上游服务器等；其模块化设计的优点是用户可以根据自身需要选择或修改某个功能模块，然后在重新编译后实现功能模块的加载。 事件驱动：异步非阻塞模型，这也是Nginx实现高性能的关键 二. Nginx的配置和使用详解首先我们先来看下未经修改的配置文件内容，nginx配置文件在${NGINX_HOME}/conf/nginx.conf。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148# 运行用户user nobody;# 启动工作进程,通常设置成和cpu的数量相等worker_processes 1;# 全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;#工作模式及连接数上限events &#123; # epoll是多路复用IO(I/O Multiplexing)中的一种方式, # 仅用于linux2.6以上内核,可以大大提高nginx的性能， # 可选参数：select、poll、kqueue、epoll、rtsig。 use epoll; # 单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 #ulimit -SHn 65535&#125;http &#123; # 设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; # 设定日志格式 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # Nginx接收到网络请求的日志文件保存路径 access_log logs/access.log main; # sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， # 对于普通应用，必须设为 on, # 如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， # 以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; # 连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; # 开启gzip压缩 gzip on; gzip_disable \"MSIE [1-6].\"; # 设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; # 设定虚拟主机配置 server &#123; # 侦听80端口 listen 80; # 定义使用什么虚拟主机地址访问，可以填写多个值，使用空格分开，支持通配符和正则 server_name localhost; # 定义服务器的默认网站根目录位置，支持相对路径和绝对路径，此处html为相对路径，等同于$&#123;NGINX_HOME&#125;/html root html; # 设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log logs/quancha.error.log; # 默认请求 location / &#123; # 定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 重定向服务器错误提示页面到静态页面/50x.html error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # 配置静态文件访问规则 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; # 过期30天，静态文件不怎么更新，过期可以设大一点， # 如果频繁更新，则可以设置得小一点。 expires 30d; &#125; # PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; # 禁止访问 .ht或.htxxx 文件 location ~ /\\.ht &#123; deny all; &#125; &#125; # HTTPS server配置规则 # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 关键配置项说明： 1. worker_processes Nginx服务器实现并发处理服务的关键，指令格式：worker_processes number | auto;number：Nginx进程最多可以产生的工作进程数量auto： Nginx进程将自动检测 2. location 指令格式：ocation [ = | ~ | ~* | ^~ ] uri {...}这里的url可以分成两类：标准uri和正则uri，区别在于uri是否包含正则表达式。 location表达式类型 = 表示对uri执行常规字符串的精确匹配，也就是完全匹配，一旦匹配成功则停止匹配其他location规则。 ~ 表示对uri执行正则匹配，区分大小写。 ~* 表示对uri执行正则匹配，不区分大小写。 ^~ 表示对uri执行常规字符串的前缀匹配而不是正则匹配，如果匹配成功，则不再匹配其他location规则。 / 表示通用匹配，如果其他匹配规则都不起作用，则所有请求都会匹配到这，因为任何请求都是以/开头。 location匹配优先级请求uri对location规则的匹配和location在配置文件中定义的顺序无关，而是根据定义的location类型确定，而且相同类型的表达式，字符串长的优先匹配，下面按照优先级从高到低对不同location表达式类型排序： = 类型表达式，优先级最高，如果匹配成功，则停止匹配。 ^~ 类型表达式，如果匹配成功，则停止匹配。 ~或~* 类型的正则表达式，以在配置文件中定义的顺序进行优先匹配。 常规字符串类型表达式，按前缀匹配。 虽然location匹配优先级与定义先后无关，但为了方便阅读，个人建议的书写顺序： 1`location = uri` &gt; `location 完整uri` &gt; `location ^~ uri` &gt; `location ~/~* uri` &gt; `loocation 部分起始uri` &gt; `location /` location规则例子： 123456789101112131415161718location = / &#123; # 这个规则很常使用，直接匹配网站根，通过域名访问网站首页，使用这条规则可以加速处理，可以转发给后端应用或静态页面 proxy_pass http://host:port/uri&#125;# 静态资源文件匹配有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location。location ^~ /static/ &#123; # 匹配任何以/static/开始的请求，并停止匹配其它 root /webroot/static/;&#125;location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; # 匹配以gif、jpg、jpeg、png、css、js、icoj结尾的请求，但是所有/static/目录的请求优先由上一条处理。 root /webroot/static/;&#125;location / &#123; # 匹配任何请求，因为所有请求都是以\"/\"开始 # 但是更长或更精确字符匹配或者正则表达式匹配会优先匹配 root /webroot/&#125; 3. log_formatMginx服务器日志相关配置项有两项 log_format:设置日志格式 log_format语法 Syntax: log_format name [escape=default|json|none] string …;Default: log_format combined “…”;Context: http 可使用全局变量 参数 说明 示例 $remote_addr 客户端地址 192.168.0.111 $remote_user 客户端用户名称 - $time_local 访问时间和时区 04/April/2019:19:00:00 +0800 $request 请求的URI和HTTP协议 “GET /index.html HTTP/1.1” $status HTTP请求状态 200 $body_bytes_sent 发送给客户端文件内容大小 3458 $http_referer url跳转来源 http://127.0.0.1/ $http_user_agent 用户终端浏览器等信息 Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36” $http_host 请求地址，即浏览器中你输入的地址（IP或域名） www.abc.com/192.168.0.222 $ssl_protocol SSL协议版本 TLSv1 $ssl_cipher 交换数据中的算法 RC4-SHA $upstream_addr 后台upstream的地址，即真正提供服务的主机地址 192.168.0.333:80 $upstream_status upstream状态 200 $request_time 整个请求的总时间 0.125 $upstream_response_time 请求过程中，upstream响应时间 0.102 如需了解更多关于Nginx变量的信息，请点击[这里](http://nginx.org/en/docs/varindex.html)。 access_log:指定日志文件存放路径、格式和缓存大小，可参考官方模块说明 ngx_http_log_module。 access_log语法 Syntax:access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];access_log off;Default:access_log logs/access.log combined;Context:http, server, location, if in location, limit_except 样例： 123access_log logs/access.log main;# 基于域名打印日志access_log logs/$host.access.log main; error_log:指定Error日志文件存放路径 error_log语法 Syntax:error_log path level;Default:error_log logs/error.log error;Context:http, server, location, if in location, limit_except level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg 参考： 官方文档之核心模块 官方文档之变量索引 nginx中文手册","categories":[{"name":"性能调优","slug":"性能调优","permalink":"https://kwilove.github.io/categories/性能调优/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://kwilove.github.io/tags/Nginx/"}]},{"title":"开博纪念","slug":"Hello-World","date":"2019-03-20T11:08:00.000Z","updated":"2019-05-23T08:48:58.420Z","comments":true,"path":"2019/03/20/Hello-World/","link":"","permalink":"https://kwilove.github.io/2019/03/20/Hello-World/","excerpt":"","text":"终于成功搭建了自己的私人博客，以前都是在CSDN等平台上发布技术相关的文章，现在可以优先上传到这里后再同步到其他平台上。 简历上也能放上自己的网址了，咱也得慢慢将档次提升上来才行。 以后有空会陆续将在其他平台发布的原创文章迁移过来，敬请期待！！！","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://kwilove.github.io/categories/杂谈/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://kwilove.github.io/tags/杂谈/"}]}]}